{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "running code invoves using scraper API, which requires api keys so may not be reproducable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "This notebook scrapes old listing data. It involves:\n",
    "1. Importing necessary libraries.\n",
    "2. Loading JSON and CSV data.\n",
    "3. Fetching and parsing HTML content.\n",
    "4. Generating URLs based on postcodes.\n",
    "5. Defining functions to extract property information.\n",
    "6. Scraping property data and storing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, sys, os\n",
    "from json import dump\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import urllib.request\n",
    "import requests\n",
    "\n",
    "# user packages\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "sys.path.append('../')\n",
    "from scripts.oldlistings import get_oldlistings_page\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# https://github.com/Elkfox/Australian-Postcode-Data/blob/master/au_postcodes.csv source of postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/landing/example_postcode.jsonl', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of postcodes defined by oldlistings\n",
    "# template is https://www.oldlistings.com.au/site-map?page=17&state=VIC\n",
    "\n",
    "\n",
    "url = \"https://www.oldlistings.com.au/site-map?page=17&state=VIC\"\n",
    "response = requests.get(url)\n",
    "\n",
    "Soup = BeautifulSoup(response.content, 'html.parser')\n",
    "Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcode = pd.read_csv(\"../data/landing/au_postcodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "postcode = postcode[postcode[\"state_code\"] == \"VIC\"]\n",
    "# restrict the postcode between 3000 and 4000\n",
    "postcode = postcode[postcode[\"postcode\"] >= 3000]\n",
    "postcode = postcode[postcode[\"postcode\"] < 4000]\n",
    "len(postcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe for urls\n",
    "url_list = []\n",
    "df = pd.DataFrame(columns=[\"url\"])\n",
    "\n",
    "# format is https://www.oldlistings.com.au/real-estate/VIC/place_name/postcode/buy/\n",
    "# if place name has space, rplace it with + sign\n",
    "\n",
    "for i in range(len(postcode)):\n",
    "    place_name = postcode.iloc[i][\"place_name\"]\n",
    "    place_name = place_name.replace(\" \", \"+\")\n",
    "    postcode_number = postcode.iloc[i][\"postcode\"]\n",
    "    url = f\"https://www.oldlistings.com.au/real-estate/VIC/{place_name}/{postcode_number}/buy/\"\n",
    "    url_list.append(url)\n",
    "\n",
    "df[\"url\"] = url_list\n",
    "\n",
    "# remove the header url\n",
    "\n",
    "df.to_csv(\"../data/curated/oldlistings_urls.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for testing using downloaded html\n",
    "# please use normal url for production\n",
    "\n",
    "# read html with bs4\n",
    "path = \"../data/landing/South Melbourne Rent Real Estate Old Listings.html\"\n",
    "\n",
    "url = \"https://www.oldlistings.com.au/real-estate/VIC/South+Melbourne/3205/buy/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "\"\"\"with open(path, 'r') as f:\n",
    "    webpage = f.read()\n",
    "\n",
    "soup = BeautifulSoup(webpage)\"\"\"\n",
    "Soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to get info from a property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(p):\n",
    "    # try to get data in json format \n",
    "    info_dict = defaultdict(None)\n",
    "    info_dict['lat'] = p.get('data-lat')\n",
    "    info_dict['lng'] = p.get('data-lng')\n",
    "    info_dict['rented_prices'] = []\n",
    "\n",
    "    p = p.find('section', {'class':\"grid-100 grid-parent\"}) # replace p with its only (useful)child\n",
    "\n",
    "    title = p.find('section', {'class':\"grid-65 tablet-grid-65 clearfix\"})\n",
    "    ad = p.find('section', {'class':\"grid-35 tablet-grid-35 price\"})\n",
    "    list_of_history = p.find('section', {'class':\"grid-100 historical-price\"})\n",
    "\n",
    "\n",
    "    # title\n",
    "    info_dict['address'] = title.find('h2', {'class': 'address'}).text\n",
    "    # other metadata: bed, bath, car etc\n",
    "    # this do not garentee any structure of the data\n",
    "    info_dict['meta_data'] = []\n",
    "    for meta_data in title.find_all('p', {'class': re.compile(\"property-meta\")}):\n",
    "        obj = {}\n",
    "        obj['label'] = meta_data.get('class')[1]\n",
    "        obj['description'] = meta_data.find('span').text.split(' ')[0]\n",
    "        obj['quantity'] = meta_data.contents[1].strip()\n",
    "        info_dict['meta_data'].append(obj)\n",
    "\n",
    "\n",
    "    # ad : we dont use ad\n",
    "\n",
    "    # list of history\n",
    "    for line in list_of_history.find('ul').find_all('li'):\n",
    "        record = {}\n",
    "        record['date'] = line.find('span').text\n",
    "        record['price'] = line.contents[1]\n",
    "        info_dict['rented_prices'].append(record)\n",
    "\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find_all('div', {'class':\"content-col\"})\n",
    "def scrape_page(soup):\n",
    "    properties = soup.find('div', {'class':\"content-col\"}).findChildren(\"div\" , recursive=False)\n",
    "    list_of_properties = []\n",
    "    for property in properties:\n",
    "        list_of_properties.append(get_info(property))\n",
    "        # get_info(property)\n",
    "    return list_of_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = scrape_page(Soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(properties)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
