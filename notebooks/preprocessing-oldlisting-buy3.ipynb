{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing oldlisting_buy_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from scripts.utils import create_dir, get_runtime\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (replace with the correct path to your CSV file)\n",
    "file_path = \"../data/landing/oldlistings_buy/oldlistings_buy_3.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Helper functions to extract and process data\n",
    "def expand_rented_prices(row):\n",
    "    try:\n",
    "        rent_list = ast.literal_eval(row['rented_prices'])\n",
    "        rows = []\n",
    "        for rent in rent_list:\n",
    "            new_row = row.copy()\n",
    "            new_row['rented_price'] = rent.get('price', None)\n",
    "            new_row['date'] = rent.get('date', None)\n",
    "            rows.append(new_row)\n",
    "        return pd.DataFrame(rows)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return pd.DataFrame([row])\n",
    "\n",
    "def extract_from_meta_data(meta_data_str, label):\n",
    "    try:\n",
    "        meta_list = ast.literal_eval(meta_data_str)\n",
    "        for item in meta_list:\n",
    "            if item.get('label') == label:\n",
    "                return item.get('quantity', None)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Apply the process to expand the first 100 rows (or all rows if needed)\n",
    "expanded_rows = pd.concat([expand_rented_prices(row) for _, row in df.iterrows()], ignore_index=True)\n",
    "\n",
    "# Extract meta_data columns for bed, bath, car, land, type\n",
    "expanded_rows['bed'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bed'))\n",
    "expanded_rows['bath'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bath'))\n",
    "expanded_rows['car'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'car'))\n",
    "expanded_rows['land'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'land'))\n",
    "expanded_rows['type'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'type'))\n",
    "\n",
    "# Keep only relevant columns\n",
    "final_expanded_df = expanded_rows[['lat', 'lng', 'address', 'bed', 'bath', 'car', 'land', 'type', 'rented_price', 'date']]\n",
    "\n",
    "# Optionally, print or view the dataframe\n",
    "# print(final_expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_translation_table = str.maketrans({\n",
    "    '０': '0', '１': '1', '２': '2', '３': '3', '４': '4', '５': '5', '６': '6', '７': '7', '８': '8', '９': '9',\n",
    "    '𝟶': '0', '𝟷': '1', '𝟸': '2', '𝟹': '3', '𝟺': '4', '𝟻': '5', '𝟼': '6', '𝟽': '7', '𝟾': '8', '𝟿': '9',\n",
    "    '𝟢': '0', '𝟣': '1', '𝟤': '2', '𝟥': '3', '𝟦': '4', '𝟧': '5', '𝟨': '6', '𝟩': '7', '𝟪': '8', '𝟫': '9',\n",
    "    '𝟘': '0', '𝟙': '1', '𝟚': '2', '𝟛': '3', '𝟜': '4', '𝟝': '5', '𝟞': '6', '𝟟': '7', '𝟠': '8', '𝟡': '9',\n",
    "    '𝞾': '0', '𝞿': '1', '𝟁': '3'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23107/1370685432.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean rented_prices\n",
    "final_expanded_df['property_price_cleaned'] = (\n",
    "    final_expanded_df['rented_price']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)           # Translate full-width digits to half-width digits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23107/2979407506.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')\n"
     ]
    }
   ],
   "source": [
    "# Replace \"O\" with \"0\" in rented_price_cleaned\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23107/2754561085.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace all non-numeric characters with NaN from rented_price_cleaned except for commas and \"$\" signs and \"-\" signs\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and handle range prices by calculating the average\n",
    "def clean_price(price):\n",
    "    if pd.isna(price):\n",
    "        return price  # Return NaN as is\n",
    "    # Handle price ranges like \"$425,000-$455,000\"\n",
    "    range_match = re.match(r\"\\$(\\d+,\\d+)-\\$(\\d+,\\d+)\", price)\n",
    "    if range_match:\n",
    "        low_price = int(range_match.group(1).replace(',', ''))\n",
    "        high_price = int(range_match.group(2).replace(',', ''))\n",
    "        return (low_price + high_price) / 2  # Return the average of the range\n",
    "    # Handle normal prices\n",
    "    price_cleaned = re.sub(r'[^\\d]', '', price)\n",
    "    return int(price_cleaned) if price_cleaned.isdigit() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23107/4207001755.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23107/483767387.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n",
      "/tmp/ipykernel_23107/483767387.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23107/2217788108.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['bed_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean \"bed\"\n",
    "final_expanded_df['bed_cleaned'] = (\n",
    "    final_expanded_df['bed']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)            # Translate full-width digits to half-width digits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"bath\"\n",
    "final_expanded_df['bath_cleaned'] = (\n",
    "    final_expanded_df['bath']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"car\"\n",
    "final_expanded_df['car_cleaned'] = (\n",
    "    final_expanded_df['car']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_digit_translation_table = str.maketrans({\n",
    "    # Uppercase letters\n",
    "    '𝙻': 'L', '𝙺': 'K', '𝙹': 'J', '𝙸': 'I', '𝙷': 'H', '𝙶': 'G', '𝙵': 'F', '𝙴': 'E', '𝙳': 'D', '𝙲': 'C', \n",
    "    '𝙱': 'B', '𝙰': 'A', '𝘾': 'C', '𝘽': 'B', '𝘼': 'A', '𝘿': 'D', '𝘡': 'Z', '𝘠': 'Y', '𝘟': 'X',\n",
    "    # Lowercase letters\n",
    "    '𝘻': 'z', '𝘺': 'y', '𝘹': 'x', '𝘸': 'w', '𝘷': 'v', '𝘶': 'u', '𝘵': 't', '𝘴': 's', '𝘳': 'r', '𝘲': 'q', \n",
    "    '𝘱': 'p', '𝘰': 'o', '𝘯': 'n', '𝘭': 'l', '𝘬': 'k', '𝘫': 'j', '𝘪': 'i', '𝘩': 'h', '𝘨': 'g', '𝘧': 'f', \n",
    "    '𝘦': 'e', '𝘥': 'd', '𝘣': 'b', '𝘢': 'a',\n",
    "    # Full-width and other non-standard digits\n",
    "    '０': '0', '１': '1', '２': '2', '３': '3', '４': '4', '５': '5', '６': '6', '７': '7', '８': '8', '９': '9',\n",
    "    '𝟶': '0', '𝟷': '1', '𝟸': '2', '𝟹': '3', '𝟺': '4', '𝟻': '5', '𝟼': '6', '𝟽': '7', '𝟾': '8', '𝟿': '9',\n",
    "    '𝟢': '0', '𝟣': '1', '𝟤': '2', '𝟥': '3', '𝟦': '4', '𝟧': '5', '𝟨': '6', '𝟩': '7', '𝟪': '8', '𝟫': '9',\n",
    "    '𝟘': '0', '𝟙': '1', '𝟚': '2', '𝟛': '3', '𝟜': '4', '𝟝': '5', '𝟞': '6', '𝟟': '7', '𝟠': '8', '𝟡': '9',\n",
    "    '𝞾': '0', '𝞿': '1', '𝟁': '3'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(letter_digit_translation_table)     # Convert full-width letters to ASCII letters\n",
    "    .str.replace(r'(\\d)O|O(\\d)', lambda m: m.group(0).replace('O', '0'), regex=True)  # Replace 'O' with '0' next to digits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "final_expanded_df = final_expanded_df.drop(columns=['rented_price', 'bed', 'bath', 'car', 'land', 'address'])\n",
    " \n",
    "# Extract year from date\n",
    "final_expanded_df['year'] = final_expanded_df['date'].dt.year\n",
    "\n",
    "# Extract suburb from address_cleaned, which is all text after the last comma\n",
    "final_expanded_df['suburb'] = final_expanded_df['address_cleaned'].str.rsplit(',').str[-1]\n",
    "\n",
    "# Remove all type that are not 'House' or 'Unit/ampt'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['type'].isin(['House', 'Unit/apmt'])]\n",
    "\n",
    "# Remove all rows with NaN in 'property_price_cleaned'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_expanded_df['bed_cleaned'] = pd.to_numeric(final_expanded_df['bed_cleaned'], errors='coerce')\n",
    "final_expanded_df['bath_cleaned'] = pd.to_numeric(final_expanded_df['bath_cleaned'], errors='coerce')\n",
    "final_expanded_df['car_cleaned'] = pd.to_numeric(final_expanded_df['car_cleaned'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>property_price_cleaned</th>\n",
       "      <th>bed_cleaned</th>\n",
       "      <th>bath_cleaned</th>\n",
       "      <th>car_cleaned</th>\n",
       "      <th>address_cleaned</th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36 LΑWLΕSS ​DR , CRANBOURNE NORTH</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>CRANBOURNE NORTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>4500000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36 LΑWLΕSS DRIVΕ, CRANBOU​RNE NORT​H</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>CRANBOU​RNE NORT​H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>787500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36 LΑWLΕSS DRIVΕ, CRANBOU​RNE NORT​H</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>CRANBOU​RNE NORT​H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14 FIELDSTONE CRESCENT, СRΑNВОՍRNΕ NОRTH</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>СRΑNВОՍRNΕ NОRTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14 FIELDSTONE CRESCENT, СRΑNВОՍRNΕ NОRTH</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>СRΑNВОՍRNΕ NОRTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519855</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>725000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5 NEPEAN STREET, WΑTSОNIΑ</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WΑTSОNIΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519856</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5 NEPEAN STREET, WΑTSОNIΑ</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WΑTSОNIΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519859</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>692500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20 PETERS STREET, WATSONIA</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WATSONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519861</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>725000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40 YERRAWA DRIVE, WATSONIA</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WATSONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519862</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>705000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23 BLACK STREET, WATSONIA</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WATSONIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195071 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat  lng   type       date  property_price_cleaned  bed_cleaned  \\\n",
       "0       NaN  NaN  House 2022-08-01                     0.0          5.0   \n",
       "2       NaN  NaN  House 2022-08-01               4500000.0          5.0   \n",
       "3       NaN  NaN  House 2022-08-01                787500.0          5.0   \n",
       "5       NaN  NaN  House 2022-08-01                720000.0          3.0   \n",
       "6       NaN  NaN  House 2022-08-01                720000.0          3.0   \n",
       "...     ...  ...    ...        ...                     ...          ...   \n",
       "519855  NaN  NaN  House 2021-07-01                725000.0          3.0   \n",
       "519856  NaN  NaN  House 2021-06-01                700000.0          3.0   \n",
       "519859  NaN  NaN  House 2021-06-01                692500.0          3.0   \n",
       "519861  NaN  NaN  House 2021-06-01                725000.0          3.0   \n",
       "519862  NaN  NaN  House 2021-06-01                705000.0          1.0   \n",
       "\n",
       "        bath_cleaned  car_cleaned                           address_cleaned  \\\n",
       "0                2.0          4.0         36 LΑWLΕSS ​DR , CRANBOURNE NORTH   \n",
       "2                2.0          4.0     36 LΑWLΕSS DRIVΕ, CRANBOU​RNE NORT​H    \n",
       "3                2.0          4.0     36 LΑWLΕSS DRIVΕ, CRANBOU​RNE NORT​H    \n",
       "5                2.0          2.0  14 FIELDSTONE CRESCENT, СRΑNВОՍRNΕ NОRTH   \n",
       "6                2.0          2.0  14 FIELDSTONE CRESCENT, СRΑNВОՍRNΕ NОRTH   \n",
       "...              ...          ...                                       ...   \n",
       "519855           1.0          1.0                 5 NEPEAN STREET, WΑTSОNIΑ   \n",
       "519856           1.0          1.0                 5 NEPEAN STREET, WΑTSОNIΑ   \n",
       "519859           1.0          2.0                20 PETERS STREET, WATSONIA   \n",
       "519861           1.0          1.0                40 YERRAWA DRIVE, WATSONIA   \n",
       "519862           3.0          2.0                 23 BLACK STREET, WATSONIA   \n",
       "\n",
       "          year                suburb  \n",
       "0       2022.0      CRANBOURNE NORTH  \n",
       "2       2022.0   CRANBOU​RNE NORT​H   \n",
       "3       2022.0   CRANBOU​RNE NORT​H   \n",
       "5       2022.0      СRΑNВОՍRNΕ NОRTH  \n",
       "6       2022.0      СRΑNВОՍRNΕ NОRTH  \n",
       "...        ...                   ...  \n",
       "519855  2021.0              WΑTSОNIΑ  \n",
       "519856  2021.0              WΑTSОNIΑ  \n",
       "519859  2021.0              WATSONIA  \n",
       "519861  2021.0              WATSONIA  \n",
       "519862  2021.0              WATSONIA  \n",
       "\n",
       "[195071 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the column 'property_price_cleaned', remove the rows that digits are more than 10\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].astype(str).str.len() <= 10]\n",
    "final_expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "      <th>avg_property_price</th>\n",
       "      <th>avg_bed</th>\n",
       "      <th>avg_bath</th>\n",
       "      <th>avg_car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA MEADOWS</td>\n",
       "      <td>592333.333333</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA NORTH</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA​ MEADO​WS</td>\n",
       "      <td>260000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTON​A MEAD​OWS</td>\n",
       "      <td>227500.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ANGLESEA</td>\n",
       "      <td>770000.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43269</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​ST ΑLВΑNS</td>\n",
       "      <td>575000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43270</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​TRUGANINA</td>\n",
       "      <td>660000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43271</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WARRNAMBOOL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43272</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WERRIBEE</td>\n",
       "      <td>506975.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43273</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WY YUNG​</td>\n",
       "      <td>435000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year             suburb  avg_property_price   avg_bed  avg_bath  \\\n",
       "0      2006.0     ALTONA MEADOWS       592333.333333  3.111111  1.888889   \n",
       "1      2006.0       ALTONA NORTH       160000.000000  1.000000  1.000000   \n",
       "2      2006.0   ALTONA​ MEADO​WS       260000.000000  3.000000  1.000000   \n",
       "3      2006.0   ALTON​A MEAD​OWS       227500.000000  2.000000  1.000000   \n",
       "4      2006.0           ANGLESEA       770000.000000  3.500000  1.500000   \n",
       "...       ...                ...                 ...       ...       ...   \n",
       "43269  2024.0         ​ST ΑLВΑNS       575000.000000  3.000000  1.000000   \n",
       "43270  2024.0         ​TRUGANINA       660000.000000  4.000000  2.000000   \n",
       "43271  2024.0      ​WARRNAMBOOL             0.000000  4.000000  2.000000   \n",
       "43272  2024.0          ​WERRIBEE       506975.000000  3.000000  1.000000   \n",
       "43273  2024.0         ​WY YUNG​        435000.000000  3.000000  2.000000   \n",
       "\n",
       "       avg_car  \n",
       "0          2.0  \n",
       "1          1.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "43269      3.0  \n",
       "43270      2.0  \n",
       "43271      4.0  \n",
       "43272      2.0  \n",
       "43273      2.0  \n",
       "\n",
       "[43274 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average property price, average bed amount, average bath amount, average car amount by year, suburb\n",
    "final_expanded_df_avg = final_expanded_df.groupby(['year', 'suburb']).agg(\n",
    "    avg_property_price=('property_price_cleaned', 'mean'),\n",
    "    avg_bed=('bed_cleaned', 'mean'),\n",
    "    avg_bath=('bath_cleaned', 'mean'),\n",
    "    avg_car=('car_cleaned', 'mean')\n",
    ").reset_index()\n",
    "final_expanded_df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df_avg.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_3_avg.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
