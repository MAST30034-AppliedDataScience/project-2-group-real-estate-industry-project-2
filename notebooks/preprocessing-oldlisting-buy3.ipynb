{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing oldlisting_buy_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from scripts.utils import create_dir, get_runtime\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (replace with the correct path to your CSV file)\n",
    "file_path = \"../data/landing/oldlistings_buy/oldlistings_buy_3.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Helper functions to extract and process data\n",
    "def expand_rented_prices(row):\n",
    "    try:\n",
    "        rent_list = ast.literal_eval(row['rented_prices'])\n",
    "        rows = []\n",
    "        for rent in rent_list:\n",
    "            new_row = row.copy()\n",
    "            new_row['rented_price'] = rent.get('price', None)\n",
    "            new_row['date'] = rent.get('date', None)\n",
    "            rows.append(new_row)\n",
    "        return pd.DataFrame(rows)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return pd.DataFrame([row])\n",
    "\n",
    "def extract_from_meta_data(meta_data_str, label):\n",
    "    try:\n",
    "        meta_list = ast.literal_eval(meta_data_str)\n",
    "        for item in meta_list:\n",
    "            if item.get('label') == label:\n",
    "                return item.get('quantity', None)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Apply the process to expand the first 100 rows (or all rows if needed)\n",
    "expanded_rows = pd.concat([expand_rented_prices(row) for _, row in df.iterrows()], ignore_index=True)\n",
    "\n",
    "# Extract meta_data columns for bed, bath, car, land, type\n",
    "expanded_rows['bed'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bed'))\n",
    "expanded_rows['bath'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bath'))\n",
    "expanded_rows['car'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'car'))\n",
    "expanded_rows['land'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'land'))\n",
    "expanded_rows['type'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'type'))\n",
    "\n",
    "# Keep only relevant columns\n",
    "final_expanded_df = expanded_rows[['lat', 'lng', 'address', 'bed', 'bath', 'car', 'land', 'type', 'rented_price', 'date']]\n",
    "\n",
    "# Optionally, print or view the dataframe\n",
    "# print(final_expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean rented_prices\n",
    "final_expanded_df['property_price_cleaned'] = (\n",
    "    final_expanded_df['rented_price']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('ï¼', '0')\n",
    "    .str.replace('ï¼‘', '1')\n",
    "    .str.replace('ï¼’', '2')\n",
    "    .str.replace('ï¼“', '3')\n",
    "    .str.replace('ï¼”', '4')\n",
    "    .str.replace('ï¼•', '5')\n",
    "    .str.replace('ï¼–', '6')\n",
    "    .str.replace('ï¼—', '7')\n",
    "    .str.replace('ï¼˜', '8')\n",
    "    .str.replace('ï¼™', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('ğŸ»', '5')\n",
    "    .str.replace('ğŸ¼', '6')\n",
    "    .str.replace('ğŸ½', '7')\n",
    "    .str.replace('ğŸ¾', '8')\n",
    "    .str.replace('ğŸ¿', '9')\n",
    "    .str.replace('ğŸ¶', '0')\n",
    "    .str.replace('ğŸ¹', '3')\n",
    "    .str.replace('ğŸº', '4')\n",
    "    .str.replace('ğŸ¸', '2')\n",
    "    .str.replace('ğŸ·', '1')\n",
    "    .str.replace('ğŸ«', '9')\n",
    "    .str.replace('ğŸª', '8')\n",
    "    .str.replace('ğŸ©', '7')\n",
    "    .str.replace('ğŸ¨', '6')\n",
    "    .str.replace('ğŸ§', '5')\n",
    "    .str.replace('ğŸ¦', '4')\n",
    "    .str.replace('ğŸ¥', '3')\n",
    "    .str.replace('ğŸ¤', '2')\n",
    "    .str.replace('ğŸ£', '1')\n",
    "    .str.replace('ğŸ¢', '0')\n",
    "    .str.replace('ğŸ¡', '9')\n",
    "    .str.replace('ğŸ ', '8')\n",
    "    .str.replace('ğŸŸ', '7')\n",
    "    .str.replace('ğŸ', '6')\n",
    "    .str.replace('ğŸ', '5')\n",
    "    .str.replace('ğŸœ', '4')\n",
    "    .str.replace('ğŸ›', '3')\n",
    "    .str.replace('ğŸš', '2')\n",
    "    .str.replace('ğŸ™', '1')\n",
    "    .str.replace('ğŸ˜', '0')\n",
    "    .str.replace('ğŸ—', '9')\n",
    "    .str.replace('ğŸ–', '8')\n",
    "    .str.replace('ğŸ•', '7')\n",
    "    .str.replace('ğŸ”', '6')\n",
    "    .str.replace('ğŸ“', '5')\n",
    "    .str.replace('ğŸ’', '4')\n",
    "    .str.replace('ğŸ‘', '3')\n",
    "    .str.replace('ğŸ', '2')\n",
    "    .str.replace('ğŸ', '1')\n",
    "    .str.replace('ğŸ', '0')\n",
    "    .str.replace('ğŸŒ', '4')\n",
    "    .str.replace('ğŸ‹', '3')\n",
    "    .str.replace('ğŸŠ', '2')\n",
    "    .str.replace('ğŸ‰', '1')\n",
    "    .str.replace('ğŸˆ', '0')\n",
    "    .str.replace('ğŸ‡', '9')\n",
    "    .str.replace('ğŸ†', '8')\n",
    "    .str.replace('ğŸ…', '7')\n",
    "    .str.replace('ğŸ„', '6')\n",
    "    .str.replace('ğŸƒ', '5')\n",
    "    .str.replace('ğŸ‚', '4')\n",
    "    .str.replace('ğŸ', '3')\n",
    "    .str.replace('ğŸ€', '2')\n",
    "    .str.replace('ğ¿', '1')\n",
    "    .str.replace('ğ¾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5717/2979407506.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')\n"
     ]
    }
   ],
   "source": [
    "# Replace \"O\" with \"0\" in rented_price_cleaned\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5717/2754561085.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace all non-numeric characters with NaN from rented_price_cleaned except for commas and \"$\" signs and \"-\" signs\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and handle range prices by calculating the average\n",
    "def clean_price(price):\n",
    "    if pd.isna(price):\n",
    "        return price  # Return NaN as is\n",
    "    # Handle price ranges like \"$425,000-$455,000\"\n",
    "    range_match = re.match(r\"\\$(\\d+,\\d+)-\\$(\\d+,\\d+)\", price)\n",
    "    if range_match:\n",
    "        low_price = int(range_match.group(1).replace(',', ''))\n",
    "        high_price = int(range_match.group(2).replace(',', ''))\n",
    "        return (low_price + high_price) / 2  # Return the average of the range\n",
    "    # Handle normal prices\n",
    "    price_cleaned = re.sub(r'[^\\d]', '', price)\n",
    "    return int(price_cleaned) if price_cleaned.isdigit() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5717/4207001755.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5717/483767387.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n",
      "/tmp/ipykernel_5717/483767387.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5717/2184586359.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['bed_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean \"bed\"\n",
    "final_expanded_df['bed_cleaned'] = (\n",
    "    final_expanded_df['bed']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('ï¼', '0')\n",
    "    .str.replace('ï¼‘', '1')\n",
    "    .str.replace('ï¼’', '2')\n",
    "    .str.replace('ï¼“', '3')\n",
    "    .str.replace('ï¼”', '4')\n",
    "    .str.replace('ï¼•', '5')\n",
    "    .str.replace('ï¼–', '6')\n",
    "    .str.replace('ï¼—', '7')\n",
    "    .str.replace('ï¼˜', '8')\n",
    "    .str.replace('ï¼™', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('ğŸ»', '5')\n",
    "    .str.replace('ğŸ¼', '6')\n",
    "    .str.replace('ğŸ½', '7')\n",
    "    .str.replace('ğŸ¾', '8')\n",
    "    .str.replace('ğŸ¿', '9')\n",
    "    .str.replace('ğŸ¶', '0')\n",
    "    .str.replace('ğŸ¹', '3')\n",
    "    .str.replace('ğŸº', '4')\n",
    "    .str.replace('ğŸ¸', '2')\n",
    "    .str.replace('ğŸ·', '1')\n",
    "    .str.replace('ğŸ«', '9')\n",
    "    .str.replace('ğŸª', '8')\n",
    "    .str.replace('ğŸ©', '7')\n",
    "    .str.replace('ğŸ¨', '6')\n",
    "    .str.replace('ğŸ§', '5')\n",
    "    .str.replace('ğŸ¦', '4')\n",
    "    .str.replace('ğŸ¥', '3')\n",
    "    .str.replace('ğŸ¤', '2')\n",
    "    .str.replace('ğŸ£', '1')\n",
    "    .str.replace('ğŸ¢', '0')\n",
    "    .str.replace('ğŸ¡', '9')\n",
    "    .str.replace('ğŸ ', '8')\n",
    "    .str.replace('ğŸŸ', '7')\n",
    "    .str.replace('ğŸ', '6')\n",
    "    .str.replace('ğŸ', '5')\n",
    "    .str.replace('ğŸœ', '4')\n",
    "    .str.replace('ğŸ›', '3')\n",
    "    .str.replace('ğŸš', '2')\n",
    "    .str.replace('ğŸ™', '1')\n",
    "    .str.replace('ğŸ˜', '0')\n",
    "    .str.replace('ğŸ—', '9')\n",
    "    .str.replace('ğŸ–', '8')\n",
    "    .str.replace('ğŸ•', '7')\n",
    "    .str.replace('ğŸ”', '6')\n",
    "    .str.replace('ğŸ“', '5')\n",
    "    .str.replace('ğŸ’', '4')\n",
    "    .str.replace('ğŸ‘', '3')\n",
    "    .str.replace('ğŸ', '2')\n",
    "    .str.replace('ğŸ', '1')\n",
    "    .str.replace('ğŸ', '0')\n",
    "    .str.replace('ğŸŒ', '4')\n",
    "    .str.replace('ğŸ‹', '3')\n",
    "    .str.replace('ğŸŠ', '2')\n",
    "    .str.replace('ğŸ‰', '1')\n",
    "    .str.replace('ğŸˆ', '0')\n",
    "    .str.replace('ğŸ‡', '9')\n",
    "    .str.replace('ğŸ†', '8')\n",
    "    .str.replace('ğŸ…', '7')\n",
    "    .str.replace('ğŸ„', '6')\n",
    "    .str.replace('ğŸƒ', '5')\n",
    "    .str.replace('ğŸ‚', '4')\n",
    "    .str.replace('ğŸ', '3')\n",
    "    .str.replace('ğŸ€', '2')\n",
    "    .str.replace('ğ¿', '1')\n",
    "    .str.replace('ğ¾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"bath\"\n",
    "final_expanded_df['bath_cleaned'] = (\n",
    "    final_expanded_df['bath']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('ï¼', '0')\n",
    "    .str.replace('ï¼‘', '1')\n",
    "    .str.replace('ï¼’', '2')\n",
    "    .str.replace('ï¼“', '3')\n",
    "    .str.replace('ï¼”', '4')\n",
    "    .str.replace('ï¼•', '5')\n",
    "    .str.replace('ï¼–', '6')\n",
    "    .str.replace('ï¼—', '7')\n",
    "    .str.replace('ï¼˜', '8')\n",
    "    .str.replace('ï¼™', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('ğŸ»', '5')\n",
    "    .str.replace('ğŸ¼', '6')\n",
    "    .str.replace('ğŸ½', '7')\n",
    "    .str.replace('ğŸ¾', '8')\n",
    "    .str.replace('ğŸ¿', '9')\n",
    "    .str.replace('ğŸ¶', '0')\n",
    "    .str.replace('ğŸ¹', '3')\n",
    "    .str.replace('ğŸº', '4')\n",
    "    .str.replace('ğŸ¸', '2')\n",
    "    .str.replace('ğŸ·', '1')\n",
    "    .str.replace('ğŸ«', '9')\n",
    "    .str.replace('ğŸª', '8')\n",
    "    .str.replace('ğŸ©', '7')\n",
    "    .str.replace('ğŸ¨', '6')\n",
    "    .str.replace('ğŸ§', '5')\n",
    "    .str.replace('ğŸ¦', '4')\n",
    "    .str.replace('ğŸ¥', '3')\n",
    "    .str.replace('ğŸ¤', '2')\n",
    "    .str.replace('ğŸ£', '1')\n",
    "    .str.replace('ğŸ¢', '0')\n",
    "    .str.replace('ğŸ¡', '9')\n",
    "    .str.replace('ğŸ ', '8')\n",
    "    .str.replace('ğŸŸ', '7')\n",
    "    .str.replace('ğŸ', '6')\n",
    "    .str.replace('ğŸ', '5')\n",
    "    .str.replace('ğŸœ', '4')\n",
    "    .str.replace('ğŸ›', '3')\n",
    "    .str.replace('ğŸš', '2')\n",
    "    .str.replace('ğŸ™', '1')\n",
    "    .str.replace('ğŸ˜', '0')\n",
    "    .str.replace('ğŸ—', '9')\n",
    "    .str.replace('ğŸ–', '8')\n",
    "    .str.replace('ğŸ•', '7')\n",
    "    .str.replace('ğŸ”', '6')\n",
    "    .str.replace('ğŸ“', '5')\n",
    "    .str.replace('ğŸ’', '4')\n",
    "    .str.replace('ğŸ‘', '3')\n",
    "    .str.replace('ğŸ', '2')\n",
    "    .str.replace('ğŸ', '1')\n",
    "    .str.replace('ğŸ', '0')\n",
    "    .str.replace('ğŸŒ', '4')\n",
    "    .str.replace('ğŸ‹', '3')\n",
    "    .str.replace('ğŸŠ', '2')\n",
    "    .str.replace('ğŸ‰', '1')\n",
    "    .str.replace('ğŸˆ', '0')\n",
    "    .str.replace('ğŸ‡', '9')\n",
    "    .str.replace('ğŸ†', '8')\n",
    "    .str.replace('ğŸ…', '7')\n",
    "    .str.replace('ğŸ„', '6')\n",
    "    .str.replace('ğŸƒ', '5')\n",
    "    .str.replace('ğŸ‚', '4')\n",
    "    .str.replace('ğŸ', '3')\n",
    "    .str.replace('ğŸ€', '2')\n",
    "    .str.replace('ğ¿', '1')\n",
    "    .str.replace('ğ¾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"car\"\n",
    "final_expanded_df['car_cleaned'] = (\n",
    "    final_expanded_df['car']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('ï¼', '0')\n",
    "    .str.replace('ï¼‘', '1')\n",
    "    .str.replace('ï¼’', '2')\n",
    "    .str.replace('ï¼“', '3')\n",
    "    .str.replace('ï¼”', '4')\n",
    "    .str.replace('ï¼•', '5')\n",
    "    .str.replace('ï¼–', '6')\n",
    "    .str.replace('ï¼—', '7')\n",
    "    .str.replace('ï¼˜', '8')\n",
    "    .str.replace('ï¼™', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('ğŸ»', '5')\n",
    "    .str.replace('ğŸ¼', '6')\n",
    "    .str.replace('ğŸ½', '7')\n",
    "    .str.replace('ğŸ¾', '8')\n",
    "    .str.replace('ğŸ¿', '9')\n",
    "    .str.replace('ğŸ¶', '0')\n",
    "    .str.replace('ğŸ¹', '3')\n",
    "    .str.replace('ğŸº', '4')\n",
    "    .str.replace('ğŸ¸', '2')\n",
    "    .str.replace('ğŸ·', '1')\n",
    "    .str.replace('ğŸ«', '9')\n",
    "    .str.replace('ğŸª', '8')\n",
    "    .str.replace('ğŸ©', '7')\n",
    "    .str.replace('ğŸ¨', '6')\n",
    "    .str.replace('ğŸ§', '5')\n",
    "    .str.replace('ğŸ¦', '4')\n",
    "    .str.replace('ğŸ¥', '3')\n",
    "    .str.replace('ğŸ¤', '2')\n",
    "    .str.replace('ğŸ£', '1')\n",
    "    .str.replace('ğŸ¢', '0')\n",
    "    .str.replace('ğŸ¡', '9')\n",
    "    .str.replace('ğŸ ', '8')\n",
    "    .str.replace('ğŸŸ', '7')\n",
    "    .str.replace('ğŸ', '6')\n",
    "    .str.replace('ğŸ', '5')\n",
    "    .str.replace('ğŸœ', '4')\n",
    "    .str.replace('ğŸ›', '3')\n",
    "    .str.replace('ğŸš', '2')\n",
    "    .str.replace('ğŸ™', '1')\n",
    "    .str.replace('ğŸ˜', '0')\n",
    "    .str.replace('ğŸ—', '9')\n",
    "    .str.replace('ğŸ–', '8')\n",
    "    .str.replace('ğŸ•', '7')\n",
    "    .str.replace('ğŸ”', '6')\n",
    "    .str.replace('ğŸ“', '5')\n",
    "    .str.replace('ğŸ’', '4')\n",
    "    .str.replace('ğŸ‘', '3')\n",
    "    .str.replace('ğŸ', '2')\n",
    "    .str.replace('ğŸ', '1')\n",
    "    .str.replace('ğŸ', '0')\n",
    "    .str.replace('ğŸŒ', '4')\n",
    "    .str.replace('ğŸ‹', '3')\n",
    "    .str.replace('ğŸŠ', '2')\n",
    "    .str.replace('ğŸ‰', '1')\n",
    "    .str.replace('ğŸˆ', '0')\n",
    "    .str.replace('ğŸ‡', '9')\n",
    "    .str.replace('ğŸ†', '8')\n",
    "    .str.replace('ğŸ…', '7')\n",
    "    .str.replace('ğŸ„', '6')\n",
    "    .str.replace('ğŸƒ', '5')\n",
    "    .str.replace('ğŸ‚', '4')\n",
    "    .str.replace('ğŸ', '3')\n",
    "    .str.replace('ğŸ€', '2')\n",
    "    .str.replace('ğ¿', '1')\n",
    "    .str.replace('ğ¾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace('ğ™»', 'L')\n",
    "    .str.replace('ğ™º', 'K')\n",
    "    .str.replace('ğ™¹', 'J')\n",
    "    .str.replace('ğ™¸', 'I')\n",
    "    .str.replace('ğ™·', 'H')\n",
    "    .str.replace('ğ™¶', 'G')\n",
    "    .str.replace('ğ™µ', 'F')\n",
    "    .str.replace('ğ™´', 'E')\n",
    "    .str.replace('ğ™³', 'D')\n",
    "    .str.replace('ğ™²', 'C')\n",
    "    .str.replace('ğ™±', 'B')\n",
    "    .str.replace('ğ™°', 'A')\n",
    "    .str.replace('ğ˜¾', 'C')\n",
    "    .str.replace('ğ˜½', 'B')\n",
    "    .str.replace('ğ˜¼', 'A')\n",
    "    .str.replace('ğ˜¿', 'D')\n",
    "    .str.replace('ğ˜¾', 'C')\n",
    "    .str.replace('ğ˜½', 'B')\n",
    "    .str.replace('ğ˜¼', 'A')\n",
    "    .str.replace('ğ˜»', 'z')\n",
    "    .str.replace('ğ˜º', 'y')\n",
    "    .str.replace('ğ˜¹', 'x')\n",
    "    .str.replace('ğ˜¸', 'w')\n",
    "    .str.replace('ğ˜·', 'v')\n",
    "    .str.replace('ğ˜¶', 'u')\n",
    "    .str.replace('ğ˜µ', 't')\n",
    "    .str.replace('ğ˜´', 's')\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address_cleaned']\n",
    "    .str.replace('ğ˜³', 'r')\n",
    "    .str.replace('ğ˜²', 'q')\n",
    "    .str.replace('ğ˜±', 'p')\n",
    "    .str.replace('ğ˜°', 'o')\n",
    "    .str.replace('ğ˜¯', 'n')\n",
    "    .str.replace('ğ˜­', 'l')\n",
    "    .str.replace('ğ˜¬', 'k')\n",
    "    .str.replace('ğ˜«', 'j')\n",
    "    .str.replace('ğ˜ª', 'i')\n",
    "    .str.replace('ğ˜©', 'h')\n",
    "    .str.replace('ğ˜¨', 'g')\n",
    "    .str.replace('ğ˜§', 'f')\n",
    "    .str.replace('ğ˜¦', 'e')\n",
    "    .str.replace('ğ˜¥', 'd')\n",
    "    .str.replace('ğ˜£', 'b')\n",
    "    .str.replace('ğ˜¢', 'a')\n",
    "    .str.replace('ğ˜¡', 'Z')\n",
    "    .str.replace('ğ˜ ', 'Y')\n",
    "    .str.replace('ğ˜Ÿ', 'X')\n",
    "    .str.replace('ï¼', '0')\n",
    "    .str.replace('ï¼‘', '1')\n",
    "    .str.replace('ï¼’', '2')\n",
    "    .str.replace('ï¼“', '3')\n",
    "    .str.replace('ï¼”', '4')\n",
    "    .str.replace('ï¼•', '5')\n",
    "    .str.replace('ï¼–', '6')\n",
    "    .str.replace('ï¼—', '7')\n",
    "    .str.replace('ï¼˜', '8')\n",
    "    .str.replace('ï¼™', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('ğŸ»', '5')\n",
    "    .str.replace('ğŸ¼', '6')\n",
    "    .str.replace('ğŸ½', '7')\n",
    "    .str.replace('ğŸ¾', '8')\n",
    "    .str.replace('ğŸ¿', '9')\n",
    "    .str.replace('ğŸ¶', '0')\n",
    "    .str.replace('ğŸ¹', '3')\n",
    "    .str.replace('ğŸº', '4')\n",
    "    .str.replace('ğŸ¸', '2')\n",
    "    .str.replace('ğŸ·', '1')\n",
    "    .str.replace('ğŸ«', '9')\n",
    "    .str.replace('ğŸª', '8')\n",
    "    .str.replace('ğŸ©', '7')\n",
    "    .str.replace('ğŸ¨', '6')\n",
    "    .str.replace('ğŸ§', '5')\n",
    "    .str.replace('ğŸ¦', '4')\n",
    "    .str.replace('ğŸ¥', '3')\n",
    "    .str.replace('ğŸ¤', '2')\n",
    "    .str.replace('ğŸ£', '1')\n",
    "    .str.replace('ğŸ¢', '0')\n",
    "    .str.replace('ğŸ¡', '9')\n",
    "    .str.replace('ğŸ ', '8')\n",
    "    .str.replace('ğŸŸ', '7')\n",
    "    .str.replace('ğŸ', '6')\n",
    "    .str.replace('ğŸ', '5')\n",
    "    .str.replace('ğŸœ', '4')\n",
    "    .str.replace('ğŸ›', '3')\n",
    "    .str.replace('ğŸš', '2')\n",
    "    .str.replace('ğŸ™', '1')\n",
    "    .str.replace('ğŸ˜', '0')\n",
    "    .str.replace('ğŸ—', '9')\n",
    "    .str.replace('ğŸ–', '8')\n",
    "    .str.replace('ğŸ•', '7')\n",
    "    .str.replace('ğŸ”', '6')\n",
    "    .str.replace('ğŸ“', '5')\n",
    "    .str.replace('ğŸ’', '4')\n",
    "    .str.replace('ğŸ‘', '3')\n",
    "    .str.replace('ğŸ', '2')\n",
    "    .str.replace('ğŸ', '1')\n",
    "    .str.replace('ğŸ', '0')\n",
    "    \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "final_expanded_df = final_expanded_df.drop(columns=['rented_price', 'bed', 'bath', 'car', 'land', 'address'])\n",
    " \n",
    "# Extract year from date\n",
    "final_expanded_df['year'] = final_expanded_df['date'].dt.year\n",
    "\n",
    "# Extract suburb from address_cleaned, which is all text after the last comma\n",
    "final_expanded_df['suburb'] = final_expanded_df['address_cleaned'].str.rsplit(',').str[-1]\n",
    "\n",
    "# Remove all type that are not 'House' or 'Unit/ampt'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['type'].isin(['House', 'Unit/apmt'])]\n",
    "\n",
    "# Remove all rows with NaN in 'property_price_cleaned'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_expanded_df['bed_cleaned'] = pd.to_numeric(final_expanded_df['bed_cleaned'], errors='coerce')\n",
    "final_expanded_df['bath_cleaned'] = pd.to_numeric(final_expanded_df['bath_cleaned'], errors='coerce')\n",
    "final_expanded_df['car_cleaned'] = pd.to_numeric(final_expanded_df['car_cleaned'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>property_price_cleaned</th>\n",
       "      <th>bed_cleaned</th>\n",
       "      <th>bath_cleaned</th>\n",
       "      <th>car_cleaned</th>\n",
       "      <th>address_cleaned</th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36 LÎ‘WLÎ•SS â€‹DRÂ , CRANBOURNE NORTH</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>CRANBOURNE NORTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>4500000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36 LÎ‘WLÎ•SS DRIVÎ•, CRANBOUâ€‹RNE NORTâ€‹H</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>CRANBOUâ€‹RNE NORTâ€‹H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>787500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36 LÎ‘WLÎ•SS DRIVÎ•, CRANBOUâ€‹RNE NORTâ€‹H</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>CRANBOUâ€‹RNE NORTâ€‹H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14 FIELDSTONE CRESCENT, Ğ¡RÎ‘NĞ’ĞÕRNÎ• NĞRTH</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Ğ¡RÎ‘NĞ’ĞÕRNÎ• NĞRTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14 FIELDSTONE CRESCENT, Ğ¡RÎ‘NĞ’ĞÕRNÎ• NĞRTH</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Ğ¡RÎ‘NĞ’ĞÕRNÎ• NĞRTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519855</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>725000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5 NEPEAN STREET, WÎ‘TSĞNIÎ‘</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WÎ‘TSĞNIÎ‘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519856</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5 NEPEAN STREET, WÎ‘TSĞNIÎ‘</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WÎ‘TSĞNIÎ‘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519859</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>692500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20 PETERS STREET, WATSONIA</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WATSONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519861</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>725000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40 YERRAWA DRIVE, WATSONIA</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WATSONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519862</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>705000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23 BLACK STREET, WATSONIA</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WATSONIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195071 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat  lng   type       date  property_price_cleaned  bed_cleaned  \\\n",
       "0       NaN  NaN  House 2022-08-01                     0.0          5.0   \n",
       "2       NaN  NaN  House 2022-08-01               4500000.0          5.0   \n",
       "3       NaN  NaN  House 2022-08-01                787500.0          5.0   \n",
       "5       NaN  NaN  House 2022-08-01                720000.0          3.0   \n",
       "6       NaN  NaN  House 2022-08-01                720000.0          3.0   \n",
       "...     ...  ...    ...        ...                     ...          ...   \n",
       "519855  NaN  NaN  House 2021-07-01                725000.0          3.0   \n",
       "519856  NaN  NaN  House 2021-06-01                700000.0          3.0   \n",
       "519859  NaN  NaN  House 2021-06-01                692500.0          3.0   \n",
       "519861  NaN  NaN  House 2021-06-01                725000.0          3.0   \n",
       "519862  NaN  NaN  House 2021-06-01                705000.0          1.0   \n",
       "\n",
       "        bath_cleaned  car_cleaned                           address_cleaned  \\\n",
       "0                2.0          4.0         36 LÎ‘WLÎ•SS â€‹DRÂ , CRANBOURNE NORTH   \n",
       "2                2.0          4.0     36 LÎ‘WLÎ•SS DRIVÎ•, CRANBOUâ€‹RNE NORTâ€‹HÂ    \n",
       "3                2.0          4.0     36 LÎ‘WLÎ•SS DRIVÎ•, CRANBOUâ€‹RNE NORTâ€‹HÂ    \n",
       "5                2.0          2.0  14 FIELDSTONE CRESCENT, Ğ¡RÎ‘NĞ’ĞÕRNÎ• NĞRTH   \n",
       "6                2.0          2.0  14 FIELDSTONE CRESCENT, Ğ¡RÎ‘NĞ’ĞÕRNÎ• NĞRTH   \n",
       "...              ...          ...                                       ...   \n",
       "519855           1.0          1.0                 5 NEPEAN STREET, WÎ‘TSĞNIÎ‘   \n",
       "519856           1.0          1.0                 5 NEPEAN STREET, WÎ‘TSĞNIÎ‘   \n",
       "519859           1.0          2.0                20 PETERS STREET, WATSONIA   \n",
       "519861           1.0          1.0                40 YERRAWA DRIVE, WATSONIA   \n",
       "519862           3.0          2.0                 23 BLACK STREET, WATSONIA   \n",
       "\n",
       "          year                suburb  \n",
       "0       2022.0      CRANBOURNE NORTH  \n",
       "2       2022.0   CRANBOUâ€‹RNE NORTâ€‹HÂ   \n",
       "3       2022.0   CRANBOUâ€‹RNE NORTâ€‹HÂ   \n",
       "5       2022.0      Ğ¡RÎ‘NĞ’ĞÕRNÎ• NĞRTH  \n",
       "6       2022.0      Ğ¡RÎ‘NĞ’ĞÕRNÎ• NĞRTH  \n",
       "...        ...                   ...  \n",
       "519855  2021.0              WÎ‘TSĞNIÎ‘  \n",
       "519856  2021.0              WÎ‘TSĞNIÎ‘  \n",
       "519859  2021.0              WATSONIA  \n",
       "519861  2021.0              WATSONIA  \n",
       "519862  2021.0              WATSONIA  \n",
       "\n",
       "[195071 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the column 'property_price_cleaned', remove the rows that digits are more than 10\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].astype(str).str.len() <= 10]\n",
    "final_expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "      <th>avg_property_price</th>\n",
       "      <th>avg_bed</th>\n",
       "      <th>avg_bath</th>\n",
       "      <th>avg_car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA MEADOWS</td>\n",
       "      <td>592333.333333</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA NORTH</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONAâ€‹ MEADOâ€‹WS</td>\n",
       "      <td>260000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONâ€‹A MEADâ€‹OWS</td>\n",
       "      <td>227500.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ANGLESEA</td>\n",
       "      <td>770000.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43269</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>â€‹ST Î‘LĞ’Î‘NS</td>\n",
       "      <td>575000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43270</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>â€‹TRUGANINA</td>\n",
       "      <td>660000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43271</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>â€‹WARRNAMBOOL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43272</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>â€‹WERRIBEE</td>\n",
       "      <td>506975.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43273</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>â€‹WY YUNGâ€‹</td>\n",
       "      <td>435000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43274 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year             suburb  avg_property_price   avg_bed  avg_bath  \\\n",
       "0      2006.0     ALTONA MEADOWS       592333.333333  3.111111  1.888889   \n",
       "1      2006.0       ALTONA NORTH       160000.000000  1.000000  1.000000   \n",
       "2      2006.0   ALTONAâ€‹ MEADOâ€‹WS       260000.000000  3.000000  1.000000   \n",
       "3      2006.0   ALTONâ€‹A MEADâ€‹OWS       227500.000000  2.000000  1.000000   \n",
       "4      2006.0           ANGLESEA       770000.000000  3.500000  1.500000   \n",
       "...       ...                ...                 ...       ...       ...   \n",
       "43269  2024.0         â€‹ST Î‘LĞ’Î‘NS       575000.000000  3.000000  1.000000   \n",
       "43270  2024.0         â€‹TRUGANINA       660000.000000  4.000000  2.000000   \n",
       "43271  2024.0      â€‹WARRNAMBOOLÂ             0.000000  4.000000  2.000000   \n",
       "43272  2024.0          â€‹WERRIBEE       506975.000000  3.000000  1.000000   \n",
       "43273  2024.0         â€‹WY YUNGâ€‹Â        435000.000000  3.000000  2.000000   \n",
       "\n",
       "       avg_car  \n",
       "0          2.0  \n",
       "1          1.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "43269      3.0  \n",
       "43270      2.0  \n",
       "43271      4.0  \n",
       "43272      2.0  \n",
       "43273      2.0  \n",
       "\n",
       "[43274 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average property price, average bed amount, average bath amount, average car amount by year, suburb\n",
    "final_expanded_df_avg = final_expanded_df.groupby(['year', 'suburb']).agg(\n",
    "    avg_property_price=('property_price_cleaned', 'mean'),\n",
    "    avg_bed=('bed_cleaned', 'mean'),\n",
    "    avg_bath=('bath_cleaned', 'mean'),\n",
    "    avg_car=('car_cleaned', 'mean')\n",
    ").reset_index()\n",
    "final_expanded_df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df_avg.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_3_avg.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
