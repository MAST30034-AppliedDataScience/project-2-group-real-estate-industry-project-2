{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing oldlisting_buy_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from scripts.utils import create_dir, get_runtime\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (replace with the correct path to your CSV file)\n",
    "file_path = \"../data/landing/oldlistings_buy/oldlistings_buy_3.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Helper functions to extract and process data\n",
    "def expand_rented_prices(row):\n",
    "    try:\n",
    "        rent_list = ast.literal_eval(row['rented_prices'])\n",
    "        rows = []\n",
    "        for rent in rent_list:\n",
    "            new_row = row.copy()\n",
    "            new_row['rented_price'] = rent.get('price', None)\n",
    "            new_row['date'] = rent.get('date', None)\n",
    "            rows.append(new_row)\n",
    "        return pd.DataFrame(rows)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return pd.DataFrame([row])\n",
    "\n",
    "def extract_from_meta_data(meta_data_str, label):\n",
    "    try:\n",
    "        meta_list = ast.literal_eval(meta_data_str)\n",
    "        for item in meta_list:\n",
    "            if item.get('label') == label:\n",
    "                return item.get('quantity', None)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Apply the process to expand the first 100 rows (or all rows if needed)\n",
    "expanded_rows = pd.concat([expand_rented_prices(row) for _, row in df.iterrows()], ignore_index=True)\n",
    "\n",
    "# Extract meta_data columns for bed, bath, car, land, type\n",
    "expanded_rows['bed'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bed'))\n",
    "expanded_rows['bath'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bath'))\n",
    "expanded_rows['car'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'car'))\n",
    "expanded_rows['land'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'land'))\n",
    "expanded_rows['type'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'type'))\n",
    "\n",
    "# Keep only relevant columns\n",
    "final_expanded_df = expanded_rows[['lat', 'lng', 'address', 'bed', 'bath', 'car', 'land', 'type', 'rented_price', 'date']]\n",
    "\n",
    "# Optionally, print or view the dataframe\n",
    "# print(final_expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean rented_prices\n",
    "final_expanded_df['property_price_cleaned'] = (\n",
    "    final_expanded_df['rented_price']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5717/2979407506.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')\n"
     ]
    }
   ],
   "source": [
    "# Replace \"O\" with \"0\" in rented_price_cleaned\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5717/2754561085.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace all non-numeric characters with NaN from rented_price_cleaned except for commas and \"$\" signs and \"-\" signs\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and handle range prices by calculating the average\n",
    "def clean_price(price):\n",
    "    if pd.isna(price):\n",
    "        return price  # Return NaN as is\n",
    "    # Handle price ranges like \"$425,000-$455,000\"\n",
    "    range_match = re.match(r\"\\$(\\d+,\\d+)-\\$(\\d+,\\d+)\", price)\n",
    "    if range_match:\n",
    "        low_price = int(range_match.group(1).replace(',', ''))\n",
    "        high_price = int(range_match.group(2).replace(',', ''))\n",
    "        return (low_price + high_price) / 2  # Return the average of the range\n",
    "    # Handle normal prices\n",
    "    price_cleaned = re.sub(r'[^\\d]', '', price)\n",
    "    return int(price_cleaned) if price_cleaned.isdigit() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5717/4207001755.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5717/483767387.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n",
      "/tmp/ipykernel_5717/483767387.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5717/2184586359.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['bed_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean \"bed\"\n",
    "final_expanded_df['bed_cleaned'] = (\n",
    "    final_expanded_df['bed']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"bath\"\n",
    "final_expanded_df['bath_cleaned'] = (\n",
    "    final_expanded_df['bath']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"car\"\n",
    "final_expanded_df['car_cleaned'] = (\n",
    "    final_expanded_df['car']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace('𝙻', 'L')\n",
    "    .str.replace('𝙺', 'K')\n",
    "    .str.replace('𝙹', 'J')\n",
    "    .str.replace('𝙸', 'I')\n",
    "    .str.replace('𝙷', 'H')\n",
    "    .str.replace('𝙶', 'G')\n",
    "    .str.replace('𝙵', 'F')\n",
    "    .str.replace('𝙴', 'E')\n",
    "    .str.replace('𝙳', 'D')\n",
    "    .str.replace('𝙲', 'C')\n",
    "    .str.replace('𝙱', 'B')\n",
    "    .str.replace('𝙰', 'A')\n",
    "    .str.replace('𝘾', 'C')\n",
    "    .str.replace('𝘽', 'B')\n",
    "    .str.replace('𝘼', 'A')\n",
    "    .str.replace('𝘿', 'D')\n",
    "    .str.replace('𝘾', 'C')\n",
    "    .str.replace('𝘽', 'B')\n",
    "    .str.replace('𝘼', 'A')\n",
    "    .str.replace('𝘻', 'z')\n",
    "    .str.replace('𝘺', 'y')\n",
    "    .str.replace('𝘹', 'x')\n",
    "    .str.replace('𝘸', 'w')\n",
    "    .str.replace('𝘷', 'v')\n",
    "    .str.replace('𝘶', 'u')\n",
    "    .str.replace('𝘵', 't')\n",
    "    .str.replace('𝘴', 's')\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address_cleaned']\n",
    "    .str.replace('𝘳', 'r')\n",
    "    .str.replace('𝘲', 'q')\n",
    "    .str.replace('𝘱', 'p')\n",
    "    .str.replace('𝘰', 'o')\n",
    "    .str.replace('𝘯', 'n')\n",
    "    .str.replace('𝘭', 'l')\n",
    "    .str.replace('𝘬', 'k')\n",
    "    .str.replace('𝘫', 'j')\n",
    "    .str.replace('𝘪', 'i')\n",
    "    .str.replace('𝘩', 'h')\n",
    "    .str.replace('𝘨', 'g')\n",
    "    .str.replace('𝘧', 'f')\n",
    "    .str.replace('𝘦', 'e')\n",
    "    .str.replace('𝘥', 'd')\n",
    "    .str.replace('𝘣', 'b')\n",
    "    .str.replace('𝘢', 'a')\n",
    "    .str.replace('𝘡', 'Z')\n",
    "    .str.replace('𝘠', 'Y')\n",
    "    .str.replace('𝘟', 'X')\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "final_expanded_df = final_expanded_df.drop(columns=['rented_price', 'bed', 'bath', 'car', 'land', 'address'])\n",
    " \n",
    "# Extract year from date\n",
    "final_expanded_df['year'] = final_expanded_df['date'].dt.year\n",
    "\n",
    "# Extract suburb from address_cleaned, which is all text after the last comma\n",
    "final_expanded_df['suburb'] = final_expanded_df['address_cleaned'].str.rsplit(',').str[-1]\n",
    "\n",
    "# Remove all type that are not 'House' or 'Unit/ampt'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['type'].isin(['House', 'Unit/apmt'])]\n",
    "\n",
    "# Remove all rows with NaN in 'property_price_cleaned'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_expanded_df['bed_cleaned'] = pd.to_numeric(final_expanded_df['bed_cleaned'], errors='coerce')\n",
    "final_expanded_df['bath_cleaned'] = pd.to_numeric(final_expanded_df['bath_cleaned'], errors='coerce')\n",
    "final_expanded_df['car_cleaned'] = pd.to_numeric(final_expanded_df['car_cleaned'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>property_price_cleaned</th>\n",
       "      <th>bed_cleaned</th>\n",
       "      <th>bath_cleaned</th>\n",
       "      <th>car_cleaned</th>\n",
       "      <th>address_cleaned</th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36 LΑWLΕSS ​DR , CRANBOURNE NORTH</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>CRANBOURNE NORTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>4500000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36 LΑWLΕSS DRIVΕ, CRANBOU​RNE NORT​H</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>CRANBOU​RNE NORT​H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>787500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36 LΑWLΕSS DRIVΕ, CRANBOU​RNE NORT​H</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>CRANBOU​RNE NORT​H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14 FIELDSTONE CRESCENT, СRΑNВОՍRNΕ NОRTH</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>СRΑNВОՍRNΕ NОRTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14 FIELDSTONE CRESCENT, СRΑNВОՍRNΕ NОRTH</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>СRΑNВОՍRNΕ NОRTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519855</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>725000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5 NEPEAN STREET, WΑTSОNIΑ</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WΑTSОNIΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519856</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5 NEPEAN STREET, WΑTSОNIΑ</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WΑTSОNIΑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519859</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>692500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20 PETERS STREET, WATSONIA</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WATSONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519861</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>725000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40 YERRAWA DRIVE, WATSONIA</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WATSONIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519862</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>705000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23 BLACK STREET, WATSONIA</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>WATSONIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195071 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat  lng   type       date  property_price_cleaned  bed_cleaned  \\\n",
       "0       NaN  NaN  House 2022-08-01                     0.0          5.0   \n",
       "2       NaN  NaN  House 2022-08-01               4500000.0          5.0   \n",
       "3       NaN  NaN  House 2022-08-01                787500.0          5.0   \n",
       "5       NaN  NaN  House 2022-08-01                720000.0          3.0   \n",
       "6       NaN  NaN  House 2022-08-01                720000.0          3.0   \n",
       "...     ...  ...    ...        ...                     ...          ...   \n",
       "519855  NaN  NaN  House 2021-07-01                725000.0          3.0   \n",
       "519856  NaN  NaN  House 2021-06-01                700000.0          3.0   \n",
       "519859  NaN  NaN  House 2021-06-01                692500.0          3.0   \n",
       "519861  NaN  NaN  House 2021-06-01                725000.0          3.0   \n",
       "519862  NaN  NaN  House 2021-06-01                705000.0          1.0   \n",
       "\n",
       "        bath_cleaned  car_cleaned                           address_cleaned  \\\n",
       "0                2.0          4.0         36 LΑWLΕSS ​DR , CRANBOURNE NORTH   \n",
       "2                2.0          4.0     36 LΑWLΕSS DRIVΕ, CRANBOU​RNE NORT​H    \n",
       "3                2.0          4.0     36 LΑWLΕSS DRIVΕ, CRANBOU​RNE NORT​H    \n",
       "5                2.0          2.0  14 FIELDSTONE CRESCENT, СRΑNВОՍRNΕ NОRTH   \n",
       "6                2.0          2.0  14 FIELDSTONE CRESCENT, СRΑNВОՍRNΕ NОRTH   \n",
       "...              ...          ...                                       ...   \n",
       "519855           1.0          1.0                 5 NEPEAN STREET, WΑTSОNIΑ   \n",
       "519856           1.0          1.0                 5 NEPEAN STREET, WΑTSОNIΑ   \n",
       "519859           1.0          2.0                20 PETERS STREET, WATSONIA   \n",
       "519861           1.0          1.0                40 YERRAWA DRIVE, WATSONIA   \n",
       "519862           3.0          2.0                 23 BLACK STREET, WATSONIA   \n",
       "\n",
       "          year                suburb  \n",
       "0       2022.0      CRANBOURNE NORTH  \n",
       "2       2022.0   CRANBOU​RNE NORT​H   \n",
       "3       2022.0   CRANBOU​RNE NORT​H   \n",
       "5       2022.0      СRΑNВОՍRNΕ NОRTH  \n",
       "6       2022.0      СRΑNВОՍRNΕ NОRTH  \n",
       "...        ...                   ...  \n",
       "519855  2021.0              WΑTSОNIΑ  \n",
       "519856  2021.0              WΑTSОNIΑ  \n",
       "519859  2021.0              WATSONIA  \n",
       "519861  2021.0              WATSONIA  \n",
       "519862  2021.0              WATSONIA  \n",
       "\n",
       "[195071 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the column 'property_price_cleaned', remove the rows that digits are more than 10\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].astype(str).str.len() <= 10]\n",
    "final_expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "      <th>avg_property_price</th>\n",
       "      <th>avg_bed</th>\n",
       "      <th>avg_bath</th>\n",
       "      <th>avg_car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA MEADOWS</td>\n",
       "      <td>592333.333333</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA NORTH</td>\n",
       "      <td>160000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA​ MEADO​WS</td>\n",
       "      <td>260000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTON​A MEAD​OWS</td>\n",
       "      <td>227500.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ANGLESEA</td>\n",
       "      <td>770000.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43269</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​ST ΑLВΑNS</td>\n",
       "      <td>575000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43270</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​TRUGANINA</td>\n",
       "      <td>660000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43271</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WARRNAMBOOL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43272</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WERRIBEE</td>\n",
       "      <td>506975.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43273</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WY YUNG​</td>\n",
       "      <td>435000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year             suburb  avg_property_price   avg_bed  avg_bath  \\\n",
       "0      2006.0     ALTONA MEADOWS       592333.333333  3.111111  1.888889   \n",
       "1      2006.0       ALTONA NORTH       160000.000000  1.000000  1.000000   \n",
       "2      2006.0   ALTONA​ MEADO​WS       260000.000000  3.000000  1.000000   \n",
       "3      2006.0   ALTON​A MEAD​OWS       227500.000000  2.000000  1.000000   \n",
       "4      2006.0           ANGLESEA       770000.000000  3.500000  1.500000   \n",
       "...       ...                ...                 ...       ...       ...   \n",
       "43269  2024.0         ​ST ΑLВΑNS       575000.000000  3.000000  1.000000   \n",
       "43270  2024.0         ​TRUGANINA       660000.000000  4.000000  2.000000   \n",
       "43271  2024.0      ​WARRNAMBOOL             0.000000  4.000000  2.000000   \n",
       "43272  2024.0          ​WERRIBEE       506975.000000  3.000000  1.000000   \n",
       "43273  2024.0         ​WY YUNG​        435000.000000  3.000000  2.000000   \n",
       "\n",
       "       avg_car  \n",
       "0          2.0  \n",
       "1          1.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "43269      3.0  \n",
       "43270      2.0  \n",
       "43271      4.0  \n",
       "43272      2.0  \n",
       "43273      2.0  \n",
       "\n",
       "[43274 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average property price, average bed amount, average bath amount, average car amount by year, suburb\n",
    "final_expanded_df_avg = final_expanded_df.groupby(['year', 'suburb']).agg(\n",
    "    avg_property_price=('property_price_cleaned', 'mean'),\n",
    "    avg_bed=('bed_cleaned', 'mean'),\n",
    "    avg_bath=('bath_cleaned', 'mean'),\n",
    "    avg_car=('car_cleaned', 'mean')\n",
    ").reset_index()\n",
    "final_expanded_df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df_avg.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_3_avg.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
