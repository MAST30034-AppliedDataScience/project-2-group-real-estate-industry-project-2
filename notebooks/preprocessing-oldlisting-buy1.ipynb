{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing oldlisting_buy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from scripts.utils import create_dir, get_runtime\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (replace with the correct path to your CSV file)\n",
    "file_path = \"../data/landing/oldlistings_buy/oldlistings_buy_1.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Helper functions to extract and process data\n",
    "def expand_rented_prices(row):\n",
    "    try:\n",
    "        rent_list = ast.literal_eval(row['rented_prices'])\n",
    "        rows = []\n",
    "        for rent in rent_list:\n",
    "            new_row = row.copy()\n",
    "            new_row['rented_price'] = rent.get('price', None)\n",
    "            new_row['date'] = rent.get('date', None)\n",
    "            rows.append(new_row)\n",
    "        return pd.DataFrame(rows)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return pd.DataFrame([row])\n",
    "\n",
    "def extract_from_meta_data(meta_data_str, label):\n",
    "    try:\n",
    "        meta_list = ast.literal_eval(meta_data_str)\n",
    "        for item in meta_list:\n",
    "            if item.get('label') == label:\n",
    "                return item.get('quantity', None)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Apply the process to expand all rows\n",
    "expanded_rows = pd.concat([expand_rented_prices(row) for _, row in df.iterrows()], ignore_index=True)\n",
    "\n",
    "# Extract meta_data columns for bed, bath, car, land, type\n",
    "expanded_rows['bed'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bed'))\n",
    "expanded_rows['bath'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bath'))\n",
    "expanded_rows['car'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'car'))\n",
    "expanded_rows['land'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'land'))\n",
    "expanded_rows['type'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'type'))\n",
    "\n",
    "# Keep only relevant columns\n",
    "final_expanded_df = expanded_rows[['lat', 'lng', 'address', 'bed', 'bath', 'car', 'land', 'type', 'rented_price', 'date']]\n",
    "\n",
    "# Optionally, print or view the dataframe\n",
    "# print(final_expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_707/2278130057.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean rented_prices\n",
    "final_expanded_df['property_price_cleaned'] = (\n",
    "    final_expanded_df['rented_price']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_707/2979407506.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')\n"
     ]
    }
   ],
   "source": [
    "# Replace \"O\" with \"0\" in rented_price_cleaned\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_707/2754561085.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace all non-numeric characters with NaN from rented_price_cleaned except for commas and \"$\" signs and \"-\" signs\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and handle range prices by calculating the average\n",
    "def clean_price(price):\n",
    "    if pd.isna(price):\n",
    "        return price  # Return NaN as is\n",
    "    # Handle price ranges like \"$425,000-$455,000\"\n",
    "    range_match = re.match(r\"\\$(\\d+,\\d+)-\\$(\\d+,\\d+)\", price)\n",
    "    if range_match:\n",
    "        low_price = int(range_match.group(1).replace(',', ''))\n",
    "        high_price = int(range_match.group(2).replace(',', ''))\n",
    "        return (low_price + high_price) / 2  # Return the average of the range\n",
    "    # Handle normal prices\n",
    "    price_cleaned = re.sub(r'[^\\d]', '', price)\n",
    "    return int(price_cleaned) if price_cleaned.isdigit() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_707/4207001755.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_707/483767387.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n",
      "/tmp/ipykernel_707/483767387.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_707/2184586359.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['bed_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean \"bed\"\n",
    "final_expanded_df['bed_cleaned'] = (\n",
    "    final_expanded_df['bed']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"bath\"\n",
    "final_expanded_df['bath_cleaned'] = (\n",
    "    final_expanded_df['bath']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"car\"\n",
    "final_expanded_df['car_cleaned'] = (\n",
    "    final_expanded_df['car']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace('𝙻', 'L')\n",
    "    .str.replace('𝙺', 'K')\n",
    "    .str.replace('𝙹', 'J')\n",
    "    .str.replace('𝙸', 'I')\n",
    "    .str.replace('𝙷', 'H')\n",
    "    .str.replace('𝙶', 'G')\n",
    "    .str.replace('𝙵', 'F')\n",
    "    .str.replace('𝙴', 'E')\n",
    "    .str.replace('𝙳', 'D')\n",
    "    .str.replace('𝙲', 'C')\n",
    "    .str.replace('𝙱', 'B')\n",
    "    .str.replace('𝙰', 'A')\n",
    "    .str.replace('𝘾', 'C')\n",
    "    .str.replace('𝘽', 'B')\n",
    "    .str.replace('𝘼', 'A')\n",
    "    .str.replace('𝘿', 'D')\n",
    "    .str.replace('𝘾', 'C')\n",
    "    .str.replace('𝘽', 'B')\n",
    "    .str.replace('𝘼', 'A')\n",
    "    .str.replace('𝘻', 'z')\n",
    "    .str.replace('𝘺', 'y')\n",
    "    .str.replace('𝘹', 'x')\n",
    "    .str.replace('𝘸', 'w')\n",
    "    .str.replace('𝘷', 'v')\n",
    "    .str.replace('𝘶', 'u')\n",
    "    .str.replace('𝘵', 't')\n",
    "    .str.replace('𝘴', 's')\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address_cleaned']\n",
    "    .str.replace('𝘳', 'r')\n",
    "    .str.replace('𝘲', 'q')\n",
    "    .str.replace('𝘱', 'p')\n",
    "    .str.replace('𝘰', 'o')\n",
    "    .str.replace('𝘯', 'n')\n",
    "    .str.replace('𝘭', 'l')\n",
    "    .str.replace('𝘬', 'k')\n",
    "    .str.replace('𝘫', 'j')\n",
    "    .str.replace('𝘪', 'i')\n",
    "    .str.replace('𝘩', 'h')\n",
    "    .str.replace('𝘨', 'g')\n",
    "    .str.replace('𝘧', 'f')\n",
    "    .str.replace('𝘦', 'e')\n",
    "    .str.replace('𝘥', 'd')\n",
    "    .str.replace('𝘣', 'b')\n",
    "    .str.replace('𝘢', 'a')\n",
    "    .str.replace('𝘡', 'Z')\n",
    "    .str.replace('𝘠', 'Y')\n",
    "    .str.replace('𝘟', 'X')\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "final_expanded_df = final_expanded_df.drop(columns=['rented_price', 'bed', 'bath', 'car', 'land', 'address'])\n",
    "\n",
    "# Extract year from date\n",
    "final_expanded_df['year'] = final_expanded_df['date'].dt.year\n",
    "\n",
    "# Extract suburb from address_cleaned, which is all text after the last comma\n",
    "final_expanded_df['suburb'] = final_expanded_df['address_cleaned'].str.rsplit(',').str[-1]\n",
    "\n",
    "# Remove all type that are not 'House' or 'Unit/ampt'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['type'].isin(['House', 'Unit/apmt'])]\n",
    "\n",
    "# Remove all rows with NaN in 'property_price_cleaned'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_expanded_df['bed_cleaned'] = pd.to_numeric(final_expanded_df['bed_cleaned'], errors='coerce')\n",
    "final_expanded_df['bath_cleaned'] = pd.to_numeric(final_expanded_df['bath_cleaned'], errors='coerce')\n",
    "final_expanded_df['car_cleaned'] = pd.to_numeric(final_expanded_df['car_cleaned'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>property_price_cleaned</th>\n",
       "      <th>bed_cleaned</th>\n",
       "      <th>bath_cleaned</th>\n",
       "      <th>car_cleaned</th>\n",
       "      <th>address_cleaned</th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35 CLIFTON AVE, STAWELL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STAWELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>179000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNIT 2, 7 SCALLAN STREET, STΑWΕLL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STΑWΕLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>179000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7 SСΑLLΑN STRΕΕT , STAWELL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STAWELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>119500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 OLIVER AVENUE, STΑWΕLL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STΑWΕLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 LONDON ROAD STREET, STAWE​LL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STAWE​LL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518323</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>575000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28 CURLEW DRIVE, C​APEL SОՍND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>C​APEL SОՍND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518325</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>625000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22 SANDPIPER CRT, CAPEL SOUND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>CAPEL SOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518326</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>605000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7/57​ WОYNΑ ΑVΕNՍΕ , СΑPΕL SОՍND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>СΑPΕL SОՍND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518338</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>432000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4 CAIN STREET, CAPEL SOUND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>CAPEL SOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518339</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>432000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4 CAIN STREET, CAPEL SOUND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>CAPEL SOUND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193602 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat  lng       type       date  property_price_cleaned  bed_cleaned  \\\n",
       "0       NaN  NaN      House 2017-05-01                105000.0          3.0   \n",
       "1       NaN  NaN  Unit/apmt 2017-05-01                179000.0          2.0   \n",
       "2       NaN  NaN  Unit/apmt 2017-05-01                179000.0          2.0   \n",
       "3       NaN  NaN      House 2017-04-01                119500.0          3.0   \n",
       "6       NaN  NaN      House 2017-04-01                129000.0          3.0   \n",
       "...     ...  ...        ...        ...                     ...          ...   \n",
       "518323  NaN  NaN      House 2019-03-01                575000.0          NaN   \n",
       "518325  NaN  NaN      House 2019-02-01                625000.0          2.0   \n",
       "518326  NaN  NaN  Unit/apmt 2019-09-01                605000.0          2.0   \n",
       "518338  NaN  NaN      House 2019-12-01                432000.0          1.0   \n",
       "518339  NaN  NaN      House 2019-12-01                432000.0          1.0   \n",
       "\n",
       "        bath_cleaned  car_cleaned                     address_cleaned    year  \\\n",
       "0                1.0          1.0             35 CLIFTON AVE, STAWELL  2017.0   \n",
       "1                1.0          1.0  UNIT 2, 7 SCALLAN STREET, STΑWΕLL   2017.0   \n",
       "2                1.0          1.0          7 SСΑLLΑN STRΕΕT , STAWELL  2017.0   \n",
       "3                1.0          1.0           2 OLIVER AVENUE, STΑWΕLL   2017.0   \n",
       "6                1.0          1.0     2 LONDON ROAD STREET, STAWE​LL   2017.0   \n",
       "...              ...          ...                                 ...     ...   \n",
       "518323           3.0          2.0       28 CURLEW DRIVE, C​APEL SОՍND  2019.0   \n",
       "518325           NaN          3.0       22 SANDPIPER CRT, CAPEL SOUND  2019.0   \n",
       "518326           2.0          1.0   7/57​ WОYNΑ ΑVΕNՍΕ , СΑPΕL SОՍND   2019.0   \n",
       "518338           3.0          5.0          4 CAIN STREET, CAPEL SOUND  2019.0   \n",
       "518339           3.0          5.0          4 CAIN STREET, CAPEL SOUND  2019.0   \n",
       "\n",
       "               suburb  \n",
       "0             STAWELL  \n",
       "1            STΑWΕLL   \n",
       "2             STAWELL  \n",
       "3            STΑWΕLL   \n",
       "6           STAWE​LL   \n",
       "...               ...  \n",
       "518323   C​APEL SОՍND  \n",
       "518325    CAPEL SOUND  \n",
       "518326   СΑPΕL SОՍND   \n",
       "518338    CAPEL SOUND  \n",
       "518339    CAPEL SOUND  \n",
       "\n",
       "[193602 rows x 11 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the column 'property_price_cleaned', remove the rows that digits are more than 10\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].astype(str).str.len() <= 10]\n",
    "final_expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "      <th>avg_property_price</th>\n",
       "      <th>avg_bed</th>\n",
       "      <th>avg_bath</th>\n",
       "      <th>avg_car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA MEADOWS</td>\n",
       "      <td>285000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA NORTH</td>\n",
       "      <td>286500.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>AL​BANVALE</td>\n",
       "      <td>359000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ANGLESEA</td>\n",
       "      <td>337000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ASPENDALE</td>\n",
       "      <td>349950.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42508</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WERRIBEE</td>\n",
       "      <td>735000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42509</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WODONGA</td>\n",
       "      <td>598000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42510</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WODONGA</td>\n",
       "      <td>604500.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42511</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WOLLERT</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42512</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WYNDHAM VΑLΕ</td>\n",
       "      <td>619500.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42513 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year           suburb  avg_property_price  avg_bed  avg_bath  avg_car\n",
       "0      2006.0   ALTONA MEADOWS            285000.0      2.0       3.0      6.0\n",
       "1      2006.0     ALTONA NORTH            286500.0      3.4       1.2      1.5\n",
       "2      2006.0       AL​BANVALE            359000.0      6.0       2.0      2.0\n",
       "3      2006.0         ANGLESEA            337000.0      3.0       1.0      NaN\n",
       "4      2006.0        ASPENDALE            349950.0      3.0       1.0      2.0\n",
       "...       ...              ...                 ...      ...       ...      ...\n",
       "42508  2024.0       ​WERRIBEE             735000.0      4.0       2.0      4.0\n",
       "42509  2024.0         ​WODONGA            598000.0      4.0       2.0      NaN\n",
       "42510  2024.0        ​WODONGA             604500.0      3.5       1.5      2.0\n",
       "42511  2024.0        ​WOLLERT             500000.0      3.0       2.0      2.0\n",
       "42512  2024.0   ​WYNDHAM VΑLΕ             619500.0      4.0       2.0      4.0\n",
       "\n",
       "[42513 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average property price, average bed amount, average bath amount, average car amount by year, suburb\n",
    "final_expanded_df_avg = final_expanded_df.groupby(['year', 'suburb']).agg(\n",
    "    avg_property_price=('property_price_cleaned', 'mean'),\n",
    "    avg_bed=('bed_cleaned', 'mean'),\n",
    "    avg_bath=('bath_cleaned', 'mean'),\n",
    "    avg_car=('car_cleaned', 'mean')\n",
    ").reset_index()\n",
    "final_expanded_df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df_avg.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_1_avg.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
