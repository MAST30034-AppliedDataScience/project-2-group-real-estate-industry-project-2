{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing oldlisting_buy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from scripts.utils import create_dir, get_runtime\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (replace with the correct path to your CSV file)\n",
    "file_path = \"../data/landing/oldlistings_buy/oldlistings_buy_1.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Helper functions to extract and process data\n",
    "def expand_rented_prices(row):\n",
    "    try:\n",
    "        rent_list = ast.literal_eval(row['rented_prices'])\n",
    "        rows = []\n",
    "        for rent in rent_list:\n",
    "            new_row = row.copy()\n",
    "            new_row['rented_price'] = rent.get('price', None)\n",
    "            new_row['date'] = rent.get('date', None)\n",
    "            rows.append(new_row)\n",
    "        return pd.DataFrame(rows)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return pd.DataFrame([row])\n",
    "\n",
    "def extract_from_meta_data(meta_data_str, label):\n",
    "    try:\n",
    "        meta_list = ast.literal_eval(meta_data_str)\n",
    "        for item in meta_list:\n",
    "            if item.get('label') == label:\n",
    "                return item.get('quantity', None)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Apply the process to expand all rows\n",
    "expanded_rows = pd.concat([expand_rented_prices(row) for _, row in df.iterrows()], ignore_index=True)\n",
    "\n",
    "# Extract meta_data columns for bed, bath, car, land, type\n",
    "expanded_rows['bed'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bed'))\n",
    "expanded_rows['bath'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bath'))\n",
    "expanded_rows['car'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'car'))\n",
    "expanded_rows['land'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'land'))\n",
    "expanded_rows['type'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'type'))\n",
    "\n",
    "# Keep only relevant columns\n",
    "final_expanded_df = expanded_rows[['lat', 'lng', 'address', 'bed', 'bath', 'car', 'land', 'type', 'rented_price', 'date']]\n",
    "\n",
    "# Optionally, print or view the dataframe\n",
    "# print(final_expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_translation_table = str.maketrans({\n",
    "    'ï¼': '0', 'ï¼‘': '1', 'ï¼’': '2', 'ï¼“': '3', 'ï¼”': '4', 'ï¼•': '5', 'ï¼–': '6', 'ï¼—': '7', 'ï¼˜': '8', 'ï¼™': '9',\n",
    "    'ğŸ¶': '0', 'ğŸ·': '1', 'ğŸ¸': '2', 'ğŸ¹': '3', 'ğŸº': '4', 'ğŸ»': '5', 'ğŸ¼': '6', 'ğŸ½': '7', 'ğŸ¾': '8', 'ğŸ¿': '9',\n",
    "    'ğŸ¢': '0', 'ğŸ£': '1', 'ğŸ¤': '2', 'ğŸ¥': '3', 'ğŸ¦': '4', 'ğŸ§': '5', 'ğŸ¨': '6', 'ğŸ©': '7', 'ğŸª': '8', 'ğŸ«': '9',\n",
    "    'ğŸ˜': '0', 'ğŸ™': '1', 'ğŸš': '2', 'ğŸ›': '3', 'ğŸœ': '4', 'ğŸ': '5', 'ğŸ': '6', 'ğŸŸ': '7', 'ğŸ ': '8', 'ğŸ¡': '9',\n",
    "    'ğ¾': '0', 'ğ¿': '1', 'ğŸ': '3'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11679/1370685432.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean rented_prices\n",
    "final_expanded_df['property_price_cleaned'] = (\n",
    "    final_expanded_df['rented_price']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)           # Translate full-width digits to half-width digits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11679/2979407506.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')\n"
     ]
    }
   ],
   "source": [
    "# Replace \"O\" with \"0\" in rented_price_cleaned\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11679/2754561085.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace all non-numeric characters with NaN from rented_price_cleaned except for commas and \"$\" signs and \"-\" signs\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and handle range prices by calculating the average\n",
    "def clean_price(price):\n",
    "    if pd.isna(price):\n",
    "        return price  # Return NaN as is\n",
    "    # Handle price ranges like \"$425,000-$455,000\"\n",
    "    range_match = re.match(r\"\\$(\\d+,\\d+)-\\$(\\d+,\\d+)\", price)\n",
    "    if range_match:\n",
    "        low_price = int(range_match.group(1).replace(',', ''))\n",
    "        high_price = int(range_match.group(2).replace(',', ''))\n",
    "        return (low_price + high_price) / 2  # Return the average of the range\n",
    "    # Handle normal prices\n",
    "    price_cleaned = re.sub(r'[^\\d]', '', price)\n",
    "    return int(price_cleaned) if price_cleaned.isdigit() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11679/4207001755.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11679/483767387.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n",
      "/tmp/ipykernel_11679/483767387.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11679/2217788108.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['bed_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean \"bed\"\n",
    "final_expanded_df['bed_cleaned'] = (\n",
    "    final_expanded_df['bed']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)            # Translate full-width digits to half-width digits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"bath\"\n",
    "final_expanded_df['bath_cleaned'] = (\n",
    "    final_expanded_df['bath']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"car\"\n",
    "final_expanded_df['car_cleaned'] = (\n",
    "    final_expanded_df['car']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_digit_translation_table = str.maketrans({\n",
    "    # Uppercase letters\n",
    "    'ğ™»': 'L', 'ğ™º': 'K', 'ğ™¹': 'J', 'ğ™¸': 'I', 'ğ™·': 'H', 'ğ™¶': 'G', 'ğ™µ': 'F', 'ğ™´': 'E', 'ğ™³': 'D', 'ğ™²': 'C', \n",
    "    'ğ™±': 'B', 'ğ™°': 'A', 'ğ˜¾': 'C', 'ğ˜½': 'B', 'ğ˜¼': 'A', 'ğ˜¿': 'D', 'ğ˜¡': 'Z', 'ğ˜ ': 'Y', 'ğ˜Ÿ': 'X',\n",
    "    # Lowercase letters\n",
    "    'ğ˜»': 'z', 'ğ˜º': 'y', 'ğ˜¹': 'x', 'ğ˜¸': 'w', 'ğ˜·': 'v', 'ğ˜¶': 'u', 'ğ˜µ': 't', 'ğ˜´': 's', 'ğ˜³': 'r', 'ğ˜²': 'q', \n",
    "    'ğ˜±': 'p', 'ğ˜°': 'o', 'ğ˜¯': 'n', 'ğ˜­': 'l', 'ğ˜¬': 'k', 'ğ˜«': 'j', 'ğ˜ª': 'i', 'ğ˜©': 'h', 'ğ˜¨': 'g', 'ğ˜§': 'f', \n",
    "    'ğ˜¦': 'e', 'ğ˜¥': 'd', 'ğ˜£': 'b', 'ğ˜¢': 'a',\n",
    "    # Full-width and other non-standard digits\n",
    "    'ï¼': '0', 'ï¼‘': '1', 'ï¼’': '2', 'ï¼“': '3', 'ï¼”': '4', 'ï¼•': '5', 'ï¼–': '6', 'ï¼—': '7', 'ï¼˜': '8', 'ï¼™': '9',\n",
    "    'ğŸ¶': '0', 'ğŸ·': '1', 'ğŸ¸': '2', 'ğŸ¹': '3', 'ğŸº': '4', 'ğŸ»': '5', 'ğŸ¼': '6', 'ğŸ½': '7', 'ğŸ¾': '8', 'ğŸ¿': '9',\n",
    "    'ğŸ¢': '0', 'ğŸ£': '1', 'ğŸ¤': '2', 'ğŸ¥': '3', 'ğŸ¦': '4', 'ğŸ§': '5', 'ğŸ¨': '6', 'ğŸ©': '7', 'ğŸª': '8', 'ğŸ«': '9',\n",
    "    'ğŸ˜': '0', 'ğŸ™': '1', 'ğŸš': '2', 'ğŸ›': '3', 'ğŸœ': '4', 'ğŸ': '5', 'ğŸ': '6', 'ğŸŸ': '7', 'ğŸ ': '8', 'ğŸ¡': '9',\n",
    "    'ğ¾': '0', 'ğ¿': '1', 'ğŸ': '3'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(letter_digit_translation_table)     # Convert full-width letters to ASCII letters\n",
    "    .str.replace(r'(\\d)O|O(\\d)', lambda m: m.group(0).replace('O', '0'), regex=True)  # Replace 'O' with '0' next to digits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "final_expanded_df = final_expanded_df.drop(columns=['rented_price', 'bed', 'bath', 'car', 'land', 'address'])\n",
    "\n",
    "# Extract year from date\n",
    "final_expanded_df['year'] = final_expanded_df['date'].dt.year\n",
    "\n",
    "# Extract suburb from address_cleaned, which is all text after the last comma\n",
    "final_expanded_df['suburb'] = final_expanded_df['address_cleaned'].str.rsplit(',').str[-1]\n",
    "\n",
    "# Remove all type that are not 'House' or 'Unit/ampt'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['type'].isin(['House', 'Unit/apmt'])]\n",
    "\n",
    "# Remove all rows with NaN in 'property_price_cleaned'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_expanded_df['bed_cleaned'] = pd.to_numeric(final_expanded_df['bed_cleaned'], errors='coerce')\n",
    "final_expanded_df['bath_cleaned'] = pd.to_numeric(final_expanded_df['bath_cleaned'], errors='coerce')\n",
    "final_expanded_df['car_cleaned'] = pd.to_numeric(final_expanded_df['car_cleaned'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>property_price_cleaned</th>\n",
       "      <th>bed_cleaned</th>\n",
       "      <th>bath_cleaned</th>\n",
       "      <th>car_cleaned</th>\n",
       "      <th>address_cleaned</th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35 CLIFTON AVE, STAWELL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STAWELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>179000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNIT 2, 7 SCALLAN STREET, STÎ‘WÎ•LL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STÎ‘WÎ•LL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>179000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7 SĞ¡Î‘LLÎ‘N STRÎ•Î•TÂ , STAWELL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STAWELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>119500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 OLIVER AVENUE, STÎ‘WÎ•LL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STÎ‘WÎ•LL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 LONDON ROAD STREET, STAWEâ€‹LL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STAWEâ€‹LL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518323</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>575000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28 CURLEW DRIVE, Câ€‹APEL SĞÕND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Câ€‹APEL SĞÕND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518325</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>625000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22 SANDPIPER CRT, CAPEL SOUND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>CAPEL SOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518326</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>605000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7/57â€‹ WĞYNÎ‘ Î‘VÎ•NÕÎ•Â , Ğ¡Î‘PÎ•L SĞÕND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Ğ¡Î‘PÎ•L SĞÕND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518338</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>432000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4 CAIN STREET, CAPEL SOUND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>CAPEL SOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518339</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>432000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4 CAIN STREET, CAPEL SOUND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>CAPEL SOUND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193602 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat  lng       type       date  property_price_cleaned  bed_cleaned  \\\n",
       "0       NaN  NaN      House 2017-05-01                105000.0          3.0   \n",
       "1       NaN  NaN  Unit/apmt 2017-05-01                179000.0          2.0   \n",
       "2       NaN  NaN  Unit/apmt 2017-05-01                179000.0          2.0   \n",
       "3       NaN  NaN      House 2017-04-01                119500.0          3.0   \n",
       "6       NaN  NaN      House 2017-04-01                129000.0          3.0   \n",
       "...     ...  ...        ...        ...                     ...          ...   \n",
       "518323  NaN  NaN      House 2019-03-01                575000.0          NaN   \n",
       "518325  NaN  NaN      House 2019-02-01                625000.0          2.0   \n",
       "518326  NaN  NaN  Unit/apmt 2019-09-01                605000.0          2.0   \n",
       "518338  NaN  NaN      House 2019-12-01                432000.0          1.0   \n",
       "518339  NaN  NaN      House 2019-12-01                432000.0          1.0   \n",
       "\n",
       "        bath_cleaned  car_cleaned                     address_cleaned    year  \\\n",
       "0                1.0          1.0             35 CLIFTON AVE, STAWELL  2017.0   \n",
       "1                1.0          1.0  UNIT 2, 7 SCALLAN STREET, STÎ‘WÎ•LLÂ   2017.0   \n",
       "2                1.0          1.0          7 SĞ¡Î‘LLÎ‘N STRÎ•Î•TÂ , STAWELL  2017.0   \n",
       "3                1.0          1.0           2 OLIVER AVENUE, STÎ‘WÎ•LLÂ   2017.0   \n",
       "6                1.0          1.0     2 LONDON ROAD STREET, STAWEâ€‹LLÂ   2017.0   \n",
       "...              ...          ...                                 ...     ...   \n",
       "518323           3.0          2.0       28 CURLEW DRIVE, Câ€‹APEL SĞÕND  2019.0   \n",
       "518325           NaN          3.0       22 SANDPIPER CRT, CAPEL SOUND  2019.0   \n",
       "518326           2.0          1.0   7/57â€‹ WĞYNÎ‘ Î‘VÎ•NÕÎ•Â , Ğ¡Î‘PÎ•L SĞÕNDÂ   2019.0   \n",
       "518338           3.0          5.0          4 CAIN STREET, CAPEL SOUND  2019.0   \n",
       "518339           3.0          5.0          4 CAIN STREET, CAPEL SOUND  2019.0   \n",
       "\n",
       "               suburb  \n",
       "0             STAWELL  \n",
       "1            STÎ‘WÎ•LLÂ   \n",
       "2             STAWELL  \n",
       "3            STÎ‘WÎ•LLÂ   \n",
       "6           STAWEâ€‹LLÂ   \n",
       "...               ...  \n",
       "518323   Câ€‹APEL SĞÕND  \n",
       "518325    CAPEL SOUND  \n",
       "518326   Ğ¡Î‘PÎ•L SĞÕNDÂ   \n",
       "518338    CAPEL SOUND  \n",
       "518339    CAPEL SOUND  \n",
       "\n",
       "[193602 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the column 'property_price_cleaned', remove the rows that digits are more than 10\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].astype(str).str.len() <= 10]\n",
    "final_expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "      <th>avg_property_price</th>\n",
       "      <th>avg_bed</th>\n",
       "      <th>avg_bath</th>\n",
       "      <th>avg_car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA MEADOWS</td>\n",
       "      <td>285000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA NORTH</td>\n",
       "      <td>286500.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALâ€‹BANVALE</td>\n",
       "      <td>359000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ANGLESEA</td>\n",
       "      <td>337000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ASPENDALE</td>\n",
       "      <td>349950.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42508</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>â€‹WERRIBEE</td>\n",
       "      <td>735000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42509</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>â€‹WODONGA</td>\n",
       "      <td>598000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42510</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>â€‹WODONGA</td>\n",
       "      <td>604500.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42511</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>â€‹WOLLERT</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42512</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>â€‹WYNDHAM VÎ‘LÎ•</td>\n",
       "      <td>619500.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42513 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year           suburb  avg_property_price  avg_bed  avg_bath  avg_car\n",
       "0      2006.0   ALTONA MEADOWS            285000.0      2.0       3.0      6.0\n",
       "1      2006.0     ALTONA NORTH            286500.0      3.4       1.2      1.5\n",
       "2      2006.0       ALâ€‹BANVALE            359000.0      6.0       2.0      2.0\n",
       "3      2006.0         ANGLESEA            337000.0      3.0       1.0      NaN\n",
       "4      2006.0        ASPENDALE            349950.0      3.0       1.0      2.0\n",
       "...       ...              ...                 ...      ...       ...      ...\n",
       "42508  2024.0       â€‹WERRIBEEÂ             735000.0      4.0       2.0      4.0\n",
       "42509  2024.0         â€‹WODONGA            598000.0      4.0       2.0      NaN\n",
       "42510  2024.0        â€‹WODONGAÂ             604500.0      3.5       1.5      2.0\n",
       "42511  2024.0        â€‹WOLLERTÂ             500000.0      3.0       2.0      2.0\n",
       "42512  2024.0   â€‹WYNDHAM VÎ‘LÎ•Â             619500.0      4.0       2.0      4.0\n",
       "\n",
       "[42513 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average property price, average bed amount, average bath amount, average car amount by year, suburb\n",
    "final_expanded_df_avg = final_expanded_df.groupby(['year', 'suburb']).agg(\n",
    "    avg_property_price=('property_price_cleaned', 'mean'),\n",
    "    avg_bed=('bed_cleaned', 'mean'),\n",
    "    avg_bath=('bath_cleaned', 'mean'),\n",
    "    avg_car=('car_cleaned', 'mean')\n",
    ").reset_index()\n",
    "final_expanded_df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df_avg.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_1_avg.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
