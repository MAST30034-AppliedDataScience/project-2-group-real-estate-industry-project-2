{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing oldlisting_buy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from scripts.utils import create_dir, get_runtime\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (replace with the correct path to your CSV file)\n",
    "file_path = \"../data/landing/oldlistings_buy/oldlistings_buy_1.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Helper functions to extract and process data\n",
    "def expand_rented_prices(row):\n",
    "    try:\n",
    "        rent_list = ast.literal_eval(row['rented_prices'])\n",
    "        rows = []\n",
    "        for rent in rent_list:\n",
    "            new_row = row.copy()\n",
    "            new_row['rented_price'] = rent.get('price', None)\n",
    "            new_row['date'] = rent.get('date', None)\n",
    "            rows.append(new_row)\n",
    "        return pd.DataFrame(rows)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return pd.DataFrame([row])\n",
    "\n",
    "def extract_from_meta_data(meta_data_str, label):\n",
    "    try:\n",
    "        meta_list = ast.literal_eval(meta_data_str)\n",
    "        for item in meta_list:\n",
    "            if item.get('label') == label:\n",
    "                return item.get('quantity', None)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Apply the process to expand all rows\n",
    "expanded_rows = pd.concat([expand_rented_prices(row) for _, row in df.iterrows()], ignore_index=True)\n",
    "\n",
    "# Extract meta_data columns for bed, bath, car, land, type\n",
    "expanded_rows['bed'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bed'))\n",
    "expanded_rows['bath'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bath'))\n",
    "expanded_rows['car'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'car'))\n",
    "expanded_rows['land'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'land'))\n",
    "expanded_rows['type'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'type'))\n",
    "\n",
    "# Keep only relevant columns\n",
    "final_expanded_df = expanded_rows[['lat', 'lng', 'address', 'bed', 'bath', 'car', 'land', 'type', 'rented_price', 'date']]\n",
    "\n",
    "# Optionally, print or view the dataframe\n",
    "# print(final_expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_translation_table = str.maketrans({\n",
    "    '０': '0', '１': '1', '２': '2', '３': '3', '４': '4', '５': '5', '６': '6', '７': '7', '８': '8', '９': '9',\n",
    "    '𝟶': '0', '𝟷': '1', '𝟸': '2', '𝟹': '3', '𝟺': '4', '𝟻': '5', '𝟼': '6', '𝟽': '7', '𝟾': '8', '𝟿': '9',\n",
    "    '𝟢': '0', '𝟣': '1', '𝟤': '2', '𝟥': '3', '𝟦': '4', '𝟧': '5', '𝟨': '6', '𝟩': '7', '𝟪': '8', '𝟫': '9',\n",
    "    '𝟘': '0', '𝟙': '1', '𝟚': '2', '𝟛': '3', '𝟜': '4', '𝟝': '5', '𝟞': '6', '𝟟': '7', '𝟠': '8', '𝟡': '9',\n",
    "    '𝞾': '0', '𝞿': '1', '𝟁': '3'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81341/1370685432.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean rented_prices\n",
    "final_expanded_df['property_price_cleaned'] = (\n",
    "    final_expanded_df['rented_price']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)           # Translate full-width digits to half-width digits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81341/2979407506.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')\n"
     ]
    }
   ],
   "source": [
    "# Replace \"O\" with \"0\" in rented_price_cleaned\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81341/2754561085.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace all non-numeric characters with NaN from rented_price_cleaned except for commas and \"$\" signs and \"-\" signs\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and handle range prices by calculating the average\n",
    "def clean_price(price):\n",
    "    if pd.isna(price):\n",
    "        return price  # Return NaN as is\n",
    "    # Handle price ranges like \"$425,000-$455,000\"\n",
    "    range_match = re.match(r\"\\$(\\d+,\\d+)-\\$(\\d+,\\d+)\", price)\n",
    "    if range_match:\n",
    "        low_price = int(range_match.group(1).replace(',', ''))\n",
    "        high_price = int(range_match.group(2).replace(',', ''))\n",
    "        return (low_price + high_price) / 2  # Return the average of the range\n",
    "    # Handle normal prices\n",
    "    price_cleaned = re.sub(r'[^\\d]', '', price)\n",
    "    return int(price_cleaned) if price_cleaned.isdigit() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81341/4207001755.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81341/483767387.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n",
      "/tmp/ipykernel_81341/483767387.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81341/2217788108.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['bed_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean \"bed\"\n",
    "final_expanded_df['bed_cleaned'] = (\n",
    "    final_expanded_df['bed']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)            # Translate full-width digits to half-width digits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"bath\"\n",
    "final_expanded_df['bath_cleaned'] = (\n",
    "    final_expanded_df['bath']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"car\"\n",
    "final_expanded_df['car_cleaned'] = (\n",
    "    final_expanded_df['car']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_digit_translation_table = str.maketrans({\n",
    "    # Uppercase letters\n",
    "    '𝙰': 'A', '𝙱': 'B', '𝙲': 'C', '𝙳': 'D', '𝙴': 'E', '𝙵': 'F', '𝙶': 'G', '𝙷': 'H', '𝙸': 'I', \n",
    "    '𝙹': 'J', '𝙺': 'K', '𝙻': 'L', '𝚀': 'Q', '𝚁': 'R', '𝚂': 'S', '𝚃': 'T', '𝚄': 'U', '𝚅': 'V', \n",
    "    '𝚆': 'W', '𝚇': 'X', '𝚈': 'Y', '𝚉': 'Z',\n",
    "    # Lowercase letters\n",
    "    '𝚊': 'a', '𝚋': 'b', '𝚌': 'c', '𝚍': 'd', '𝚎': 'e', \n",
    "    '𝚏': 'f', '𝚐': 'g', '𝚑': 'h', '𝚒': 'i', '𝚓': 'j', '𝚔': 'k', '𝚕': 'l', '𝚖': 'm', '𝚗': 'n', \n",
    "    '𝚘': 'o', '𝚙': 'p', '𝚚': 'q', '𝚛': 'r', '𝚜': 's', '𝚝': 't', '𝚞': 'u', '𝚟': 'v', '𝚠': 'w', \n",
    "    '𝚡': 'x', '𝚢': 'y', '𝚣': 'z',\n",
    "    # Full-width and other non-standard digits\n",
    "    '０': '0', '１': '1', '２': '2', '３': '3', '４': '4', '５': '5', '６': '6', '７': '7', '８': '8', '９': '9',\n",
    "    '𝟶': '0', '𝟷': '1', '𝟸': '2', '𝟹': '3', '𝟺': '4', '𝟻': '5', '𝟼': '6', '𝟽': '7', '𝟾': '8', '𝟿': '9',\n",
    "    '𝟢': '0', '𝟣': '1', '𝟤': '2', '𝟥': '3', '𝟦': '4', '𝟧': '5', '𝟨': '6', '𝟩': '7', '𝟪': '8', '𝟫': '9',\n",
    "    '𝟘': '0', '𝟙': '1', '𝟚': '2', '𝟛': '3', '𝟜': '4', '𝟝': '5', '𝟞': '6', '𝟟': '7', '𝟠': '8', '𝟡': '9',\n",
    "    '𝞾': '0', '𝞿': '1', '𝟁': '3'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address']\n",
    "    .str.replace('\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace('\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace('<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace('</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace('<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace('</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(letter_digit_translation_table)     # Convert full-width letters to ASCII letters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "final_expanded_df = final_expanded_df.drop(columns=['rented_price', 'bed', 'bath', 'car', 'land', 'address'])\n",
    " \n",
    "# Extract year from date\n",
    "final_expanded_df['year'] = final_expanded_df['date'].dt.year\n",
    "\n",
    "# Extract suburb from address_cleaned, which is all text after the last comma\n",
    "final_expanded_df['suburb'] = final_expanded_df['address_cleaned'].str.rsplit(',').str[-1].str.strip()\n",
    "\n",
    "# Remove all type that are not 'House' or 'Unit/ampt'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['type'].isin(['House', 'Unit/apmt'])]\n",
    "\n",
    "# Remove all rows with NaN in 'property_price_cleaned'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract suburb from address_cleaned, which is all text after the last comma\n",
    "final_expanded_df['suburb'] = final_expanded_df['address_cleaned'].str.rsplit(',').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_expanded_df['bed_cleaned'] = pd.to_numeric(final_expanded_df['bed_cleaned'], errors='coerce')\n",
    "final_expanded_df['bath_cleaned'] = pd.to_numeric(final_expanded_df['bath_cleaned'], errors='coerce')\n",
    "final_expanded_df['car_cleaned'] = pd.to_numeric(final_expanded_df['car_cleaned'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>property_price_cleaned</th>\n",
       "      <th>bed_cleaned</th>\n",
       "      <th>bath_cleaned</th>\n",
       "      <th>car_cleaned</th>\n",
       "      <th>address_cleaned</th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35 CLIFTON AVE, STAWELL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STAWELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>179000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNIT 2, 7 SCALLAN STREET, STΑWΕLL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STΑWΕLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>179000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7 SСΑLLΑN STRΕΕT, STAWELL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STAWELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>119500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 OLIVER AVENUE, STΑWΕLL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STΑWΕLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 LONDON ROAD STREET, STAWELL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>STAWELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518323</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>575000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28 CURLEW DRIVE, CAPEL SОՍND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>CAPEL SОՍND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518325</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>625000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22 SANDPIPER CRT, CAPEL SOUND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>CAPEL SOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518326</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>605000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7/57 WОYNΑ ΑVΕNՍΕ, СΑPΕL SОՍND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>СΑPΕL SОՍND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518338</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>432000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4 CAIN STREET, CAPEL SOUND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>CAPEL SOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518339</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>432000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4 CAIN STREET, CAPEL SOUND</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>CAPEL SOUND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193602 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat  lng       type       date  property_price_cleaned  bed_cleaned  \\\n",
       "0       NaN  NaN      House 2017-05-01                105000.0          3.0   \n",
       "1       NaN  NaN  Unit/apmt 2017-05-01                179000.0          2.0   \n",
       "2       NaN  NaN  Unit/apmt 2017-05-01                179000.0          2.0   \n",
       "3       NaN  NaN      House 2017-04-01                119500.0          3.0   \n",
       "6       NaN  NaN      House 2017-04-01                129000.0          3.0   \n",
       "...     ...  ...        ...        ...                     ...          ...   \n",
       "518323  NaN  NaN      House 2019-03-01                575000.0          NaN   \n",
       "518325  NaN  NaN      House 2019-02-01                625000.0          2.0   \n",
       "518326  NaN  NaN  Unit/apmt 2019-09-01                605000.0          2.0   \n",
       "518338  NaN  NaN      House 2019-12-01                432000.0          1.0   \n",
       "518339  NaN  NaN      House 2019-12-01                432000.0          1.0   \n",
       "\n",
       "        bath_cleaned  car_cleaned                    address_cleaned    year  \\\n",
       "0                1.0          1.0            35 CLIFTON AVE, STAWELL  2017.0   \n",
       "1                1.0          1.0  UNIT 2, 7 SCALLAN STREET, STΑWΕLL  2017.0   \n",
       "2                1.0          1.0          7 SСΑLLΑN STRΕΕT, STAWELL  2017.0   \n",
       "3                1.0          1.0           2 OLIVER AVENUE, STΑWΕLL  2017.0   \n",
       "6                1.0          1.0      2 LONDON ROAD STREET, STAWELL  2017.0   \n",
       "...              ...          ...                                ...     ...   \n",
       "518323           3.0          2.0       28 CURLEW DRIVE, CAPEL SОՍND  2019.0   \n",
       "518325           NaN          3.0      22 SANDPIPER CRT, CAPEL SOUND  2019.0   \n",
       "518326           2.0          1.0     7/57 WОYNΑ ΑVΕNՍΕ, СΑPΕL SОՍND  2019.0   \n",
       "518338           3.0          5.0         4 CAIN STREET, CAPEL SOUND  2019.0   \n",
       "518339           3.0          5.0         4 CAIN STREET, CAPEL SOUND  2019.0   \n",
       "\n",
       "              suburb  \n",
       "0            STAWELL  \n",
       "1            STΑWΕLL  \n",
       "2            STAWELL  \n",
       "3            STΑWΕLL  \n",
       "6            STAWELL  \n",
       "...              ...  \n",
       "518323   CAPEL SОՍND  \n",
       "518325   CAPEL SOUND  \n",
       "518326   СΑPΕL SОՍND  \n",
       "518338   CAPEL SOUND  \n",
       "518339   CAPEL SOUND  \n",
       "\n",
       "[193602 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the column 'property_price_cleaned', remove the rows that digits are more than 10\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].astype(str).str.len() <= 10]\n",
    "final_expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "      <th>avg_property_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALBANVALE</td>\n",
       "      <td>3.590000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA MEADOWS</td>\n",
       "      <td>2.850000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA NORTH</td>\n",
       "      <td>2.804167e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA NОRTH</td>\n",
       "      <td>2.950000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ANGLESEA</td>\n",
       "      <td>3.370000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19883</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>ԌLΕN IRIS</td>\n",
       "      <td>1.361250e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19884</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>ԌRΕΕNVΑLΕ</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19885</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>ԌRОVΕDΑLΕ</td>\n",
       "      <td>1.437357e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19886</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>ԌΕMВRООK</td>\n",
       "      <td>9.243333e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19887</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>ԌΕΕLОNԌ</td>\n",
       "      <td>5.716667e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19888 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year           suburb  avg_property_price\n",
       "0      2006.0        ALBANVALE        3.590000e+05\n",
       "1      2006.0   ALTONA MEADOWS        2.850000e+05\n",
       "2      2006.0     ALTONA NORTH        2.804167e+05\n",
       "3      2006.0     ALTONA NОRTH        2.950000e+05\n",
       "4      2006.0         ANGLESEA        3.370000e+05\n",
       "...       ...              ...                 ...\n",
       "19883  2024.0        ԌLΕN IRIS        1.361250e+06\n",
       "19884  2024.0        ԌRΕΕNVΑLΕ        0.000000e+00\n",
       "19885  2024.0        ԌRОVΕDΑLΕ        1.437357e+06\n",
       "19886  2024.0         ԌΕMВRООK        9.243333e+05\n",
       "19887  2024.0          ԌΕΕLОNԌ        5.716667e+05\n",
       "\n",
       "[19888 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average property price by year, suburb\n",
    "final_expanded_df_avg = final_expanded_df.groupby(['year', 'suburb']).agg(\n",
    "    avg_property_price=('property_price_cleaned', 'mean'),\n",
    ").reset_index()\n",
    "final_expanded_df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the leading and trailing whitespaces from the suburb column\n",
    "final_expanded_df_avg['suburb'] = final_expanded_df_avg['suburb'].str.strip()\n",
    "\n",
    "# convert 'year' to int\n",
    "final_expanded_df_avg['year'] = final_expanded_df_avg['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df_avg.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_1_avg.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
