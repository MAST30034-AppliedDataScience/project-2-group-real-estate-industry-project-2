{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing oldlisting_buy_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from scripts.utils import create_dir, get_runtime\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (replace with the correct path to your CSV file)\n",
    "file_path = \"../data/landing/oldlistings_buy/oldlistings_buy_4.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Helper functions to extract and process data\n",
    "def expand_rented_prices(row):\n",
    "    try:\n",
    "        rent_list = ast.literal_eval(row['rented_prices'])\n",
    "        rows = []\n",
    "        for rent in rent_list:\n",
    "            new_row = row.copy()\n",
    "            new_row['rented_price'] = rent.get('price', None)\n",
    "            new_row['date'] = rent.get('date', None)\n",
    "            rows.append(new_row)\n",
    "        return pd.DataFrame(rows)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return pd.DataFrame([row])\n",
    "\n",
    "def extract_from_meta_data(meta_data_str, label):\n",
    "    try:\n",
    "        meta_list = ast.literal_eval(meta_data_str)\n",
    "        for item in meta_list:\n",
    "            if item.get('label') == label:\n",
    "                return item.get('quantity', None)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Apply the process to expand the first 100 rows (or all rows if needed)\n",
    "expanded_rows = pd.concat([expand_rented_prices(row) for _, row in df.iterrows()], ignore_index=True)\n",
    "\n",
    "# Extract meta_data columns for bed, bath, car, land, type\n",
    "expanded_rows['bed'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bed'))\n",
    "expanded_rows['bath'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bath'))\n",
    "expanded_rows['car'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'car'))\n",
    "expanded_rows['land'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'land'))\n",
    "expanded_rows['type'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'type'))\n",
    "\n",
    "# Keep only relevant columns\n",
    "final_expanded_df = expanded_rows[['lat', 'lng', 'address', 'bed', 'bath', 'car', 'land', 'type', 'rented_price', 'date']]\n",
    "\n",
    "# Optionally, print or view the dataframe\n",
    "# print(final_expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_translation_table = str.maketrans({\n",
    "    'ï¼': '0', 'ï¼‘': '1', 'ï¼’': '2', 'ï¼“': '3', 'ï¼”': '4', 'ï¼•': '5', 'ï¼–': '6', 'ï¼—': '7', 'ï¼˜': '8', 'ï¼™': '9',\n",
    "    'ğŸ¶': '0', 'ğŸ·': '1', 'ğŸ¸': '2', 'ğŸ¹': '3', 'ğŸº': '4', 'ğŸ»': '5', 'ğŸ¼': '6', 'ğŸ½': '7', 'ğŸ¾': '8', 'ğŸ¿': '9',\n",
    "    'ğŸ¢': '0', 'ğŸ£': '1', 'ğŸ¤': '2', 'ğŸ¥': '3', 'ğŸ¦': '4', 'ğŸ§': '5', 'ğŸ¨': '6', 'ğŸ©': '7', 'ğŸª': '8', 'ğŸ«': '9',\n",
    "    'ğŸ˜': '0', 'ğŸ™': '1', 'ğŸš': '2', 'ğŸ›': '3', 'ğŸœ': '4', 'ğŸ': '5', 'ğŸ': '6', 'ğŸŸ': '7', 'ğŸ ': '8', 'ğŸ¡': '9',\n",
    "    'ğ¾': '0', 'ğ¿': '1', 'ğŸ': '3'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1188/1370685432.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean rented_prices\n",
    "final_expanded_df['property_price_cleaned'] = (\n",
    "    final_expanded_df['rented_price']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)           # Translate full-width digits to half-width digits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1188/2979407506.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')\n"
     ]
    }
   ],
   "source": [
    "# Replace \"O\" with \"0\" in rented_price_cleaned\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1188/2754561085.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace all non-numeric characters with NaN from rented_price_cleaned except for commas and \"$\" signs and \"-\" signs\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and handle range prices by calculating the average\n",
    "def clean_price(price):\n",
    "    if pd.isna(price):\n",
    "        return price  # Return NaN as is\n",
    "    # Handle price ranges like \"$425,000-$455,000\"\n",
    "    range_match = re.match(r\"\\$(\\d+,\\d+)-\\$(\\d+,\\d+)\", price)\n",
    "    if range_match:\n",
    "        low_price = int(range_match.group(1).replace(',', ''))\n",
    "        high_price = int(range_match.group(2).replace(',', ''))\n",
    "        return (low_price + high_price) / 2  # Return the average of the range\n",
    "    # Handle normal prices\n",
    "    price_cleaned = re.sub(r'[^\\d]', '', price)\n",
    "    return int(price_cleaned) if price_cleaned.isdigit() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1188/4207001755.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1188/483767387.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n",
      "/tmp/ipykernel_1188/483767387.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1188/2217788108.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['bed_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean \"bed\"\n",
    "final_expanded_df['bed_cleaned'] = (\n",
    "    final_expanded_df['bed']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)            # Translate full-width digits to half-width digits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"bath\"\n",
    "final_expanded_df['bath_cleaned'] = (\n",
    "    final_expanded_df['bath']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"car\"\n",
    "final_expanded_df['car_cleaned'] = (\n",
    "    final_expanded_df['car']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace(r'<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace(r'</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(digit_translation_table)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_digit_translation_table = str.maketrans({\n",
    "    # Uppercase letters\n",
    "    'ğ™°': 'A', 'ğ™±': 'B', 'ğ™²': 'C', 'ğ™³': 'D', 'ğ™´': 'E', 'ğ™µ': 'F', 'ğ™¶': 'G', 'ğ™·': 'H', 'ğ™¸': 'I', \n",
    "    'ğ™¹': 'J', 'ğ™º': 'K', 'ğ™»': 'L', 'ğš€': 'Q', 'ğš': 'R', 'ğš‚': 'S', 'ğšƒ': 'T', 'ğš„': 'U', 'ğš…': 'V', \n",
    "    'ğš†': 'W', 'ğš‡': 'X', 'ğšˆ': 'Y', 'ğš‰': 'Z',\n",
    "    # Lowercase letters\n",
    "    'ğšŠ': 'a', 'ğš‹': 'b', 'ğšŒ': 'c', 'ğš': 'd', 'ğš': 'e', \n",
    "    'ğš': 'f', 'ğš': 'g', 'ğš‘': 'h', 'ğš’': 'i', 'ğš“': 'j', 'ğš”': 'k', 'ğš•': 'l', 'ğš–': 'm', 'ğš—': 'n', \n",
    "    'ğš˜': 'o', 'ğš™': 'p', 'ğšš': 'q', 'ğš›': 'r', 'ğšœ': 's', 'ğš': 't', 'ğš': 'u', 'ğšŸ': 'v', 'ğš ': 'w', \n",
    "    'ğš¡': 'x', 'ğš¢': 'y', 'ğš£': 'z',\n",
    "    # Full-width and other non-standard digits\n",
    "    'ï¼': '0', 'ï¼‘': '1', 'ï¼’': '2', 'ï¼“': '3', 'ï¼”': '4', 'ï¼•': '5', 'ï¼–': '6', 'ï¼—': '7', 'ï¼˜': '8', 'ï¼™': '9',\n",
    "    'ğŸ¶': '0', 'ğŸ·': '1', 'ğŸ¸': '2', 'ğŸ¹': '3', 'ğŸº': '4', 'ğŸ»': '5', 'ğŸ¼': '6', 'ğŸ½': '7', 'ğŸ¾': '8', 'ğŸ¿': '9',\n",
    "    'ğŸ¢': '0', 'ğŸ£': '1', 'ğŸ¤': '2', 'ğŸ¥': '3', 'ğŸ¦': '4', 'ğŸ§': '5', 'ğŸ¨': '6', 'ğŸ©': '7', 'ğŸª': '8', 'ğŸ«': '9',\n",
    "    'ğŸ˜': '0', 'ğŸ™': '1', 'ğŸš': '2', 'ğŸ›': '3', 'ğŸœ': '4', 'ğŸ': '5', 'ğŸ': '6', 'ğŸŸ': '7', 'ğŸ ': '8', 'ğŸ¡': '9',\n",
    "    'ğ¾': '0', 'ğ¿': '1', 'ğŸ': '3'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address']\n",
    "    .str.replace('\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace('\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace('<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace('</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace('<SPAN>', '', regex=False)           # Remove <SPAN> tag\n",
    "    .str.replace('</SPAN>', '', regex=False)          # Remove </SPAN> tag\n",
    "    .str.translate(letter_digit_translation_table)     # Convert full-width letters to ASCII letters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "final_expanded_df = final_expanded_df.drop(columns=['rented_price', 'bed', 'bath', 'car', 'land', 'address'])\n",
    " \n",
    "# Extract year from date\n",
    "final_expanded_df['year'] = final_expanded_df['date'].dt.year\n",
    "\n",
    "# Extract suburb from address_cleaned, which is all text after the last comma, removing leading and trailing whitespaces\n",
    "final_expanded_df['suburb'] = final_expanded_df['address_cleaned'].str.split(',').str[-1].str.strip()\n",
    "\n",
    "# Remove all type that are not 'House' or 'Unit/ampt'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['type'].isin(['House', 'Unit/apmt'])]\n",
    "\n",
    "# Remove all rows with NaN in 'property_price_cleaned'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract suburb from address_cleaned, which is all text after the last comma\n",
    "final_expanded_df['suburb'] = final_expanded_df['address_cleaned'].str.rsplit(',').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_expanded_df['bed_cleaned'] = pd.to_numeric(final_expanded_df['bed_cleaned'], errors='coerce')\n",
    "final_expanded_df['bath_cleaned'] = pd.to_numeric(final_expanded_df['bath_cleaned'], errors='coerce')\n",
    "final_expanded_df['car_cleaned'] = pd.to_numeric(final_expanded_df['car_cleaned'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>property_price_cleaned</th>\n",
       "      <th>bed_cleaned</th>\n",
       "      <th>bath_cleaned</th>\n",
       "      <th>car_cleaned</th>\n",
       "      <th>address_cleaned</th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-37.4807</td>\n",
       "      <td>144.50439</td>\n",
       "      <td>House</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>810000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>936 BACCHUS MARSH ROAD, BULLENGAROOK</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>BULLENGAROOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-37.4807</td>\n",
       "      <td>144.50439</td>\n",
       "      <td>House</td>\n",
       "      <td>2010-05-01</td>\n",
       "      <td>795000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>936 BACCHUS MARSH ROAD, BULLENGAROOK</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>BULLENGAROOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-37.4807</td>\n",
       "      <td>144.50439</td>\n",
       "      <td>House</td>\n",
       "      <td>2009-08-01</td>\n",
       "      <td>795000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>936 BACCHUS MARSH ROAD, BULLENGAROOK</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>BULLENGAROOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-37.4807</td>\n",
       "      <td>144.50439</td>\n",
       "      <td>House</td>\n",
       "      <td>2009-05-01</td>\n",
       "      <td>795000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>936 BACCHUS MARSH ROAD, BULLENGAROOK</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>BULLENGAROOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-37.4807</td>\n",
       "      <td>144.50439</td>\n",
       "      <td>House</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>795000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>936 BACCHUS MARSH ROAD, BULLENGAROOK</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>BULLENGAROOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520809</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175 HURD STRÎ•Î•T, PORTLAND</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>PORTLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520810</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2010-08-01</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175 HURD STRÎ•Î•T, PORTLAND</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>PORTLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520811</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2009-08-01</td>\n",
       "      <td>119900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175 HURD STRÎ•Î•T, PORTLAND</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>PORTLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520815</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>1150000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84 BARKLY STREET, PORTLAND</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>PORTLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520816</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2010-06-01</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84 BARKLY STREET, PORTLAND</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>PORTLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197638 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat        lng       type       date  property_price_cleaned  \\\n",
       "7      -37.4807  144.50439      House 2015-01-01                810000.0   \n",
       "8      -37.4807  144.50439      House 2010-05-01                795000.0   \n",
       "9      -37.4807  144.50439      House 2009-08-01                795000.0   \n",
       "10     -37.4807  144.50439      House 2009-05-01                795000.0   \n",
       "11     -37.4807  144.50439      House 2009-01-01                795000.0   \n",
       "...         ...        ...        ...        ...                     ...   \n",
       "520809      NaN        NaN  Unit/apmt 2016-12-01                 85000.0   \n",
       "520810      NaN        NaN  Unit/apmt 2010-08-01                120000.0   \n",
       "520811      NaN        NaN  Unit/apmt 2009-08-01                119900.0   \n",
       "520815      NaN        NaN  Unit/apmt 2016-12-01               1150000.0   \n",
       "520816      NaN        NaN  Unit/apmt 2010-06-01                155000.0   \n",
       "\n",
       "        bed_cleaned  bath_cleaned  car_cleaned  \\\n",
       "7               4.0           2.0          8.0   \n",
       "8               4.0           2.0          8.0   \n",
       "9               4.0           2.0          8.0   \n",
       "10              4.0           2.0          8.0   \n",
       "11              4.0           2.0          8.0   \n",
       "...             ...           ...          ...   \n",
       "520809          2.0           1.0          1.0   \n",
       "520810          2.0           1.0          1.0   \n",
       "520811          2.0           1.0          1.0   \n",
       "520815          2.0           1.0          1.0   \n",
       "520816          2.0           1.0          1.0   \n",
       "\n",
       "                             address_cleaned    year         suburb  \n",
       "7       936 BACCHUS MARSH ROAD, BULLENGAROOK  2015.0   BULLENGAROOK  \n",
       "8       936 BACCHUS MARSH ROAD, BULLENGAROOK  2010.0   BULLENGAROOK  \n",
       "9       936 BACCHUS MARSH ROAD, BULLENGAROOK  2009.0   BULLENGAROOK  \n",
       "10      936 BACCHUS MARSH ROAD, BULLENGAROOK  2009.0   BULLENGAROOK  \n",
       "11      936 BACCHUS MARSH ROAD, BULLENGAROOK  2009.0   BULLENGAROOK  \n",
       "...                                      ...     ...            ...  \n",
       "520809             175 HURD STRÎ•Î•T, PORTLAND  2016.0       PORTLAND  \n",
       "520810             175 HURD STRÎ•Î•T, PORTLAND  2010.0       PORTLAND  \n",
       "520811             175 HURD STRÎ•Î•T, PORTLAND  2009.0       PORTLAND  \n",
       "520815            84 BARKLY STREET, PORTLAND  2016.0       PORTLAND  \n",
       "520816            84 BARKLY STREET, PORTLAND  2010.0       PORTLAND  \n",
       "\n",
       "[197638 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the column 'property_price_cleaned', remove the rows that digits are more than 10\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].astype(str).str.len() <= 10]\n",
    "final_expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "      <th>avg_property_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALBION</td>\n",
       "      <td>152500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA MEADOWS</td>\n",
       "      <td>290000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ASPENDALE GARDENS</td>\n",
       "      <td>388600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>BADDAGINNIE</td>\n",
       "      <td>185000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>BALWYN</td>\n",
       "      <td>900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19904</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>Ğ¡ĞĞ¡KÎ‘TĞĞ</td>\n",
       "      <td>755000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19905</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>ÔŒLÎ•N IRIS</td>\n",
       "      <td>325000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19906</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>ÔŒRÎ•Î•NVÎ‘LÎ•</td>\n",
       "      <td>929000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19907</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>ÔŒRĞVÎ•DÎ‘LÎ•</td>\n",
       "      <td>612250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19908</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>ÔŒÎ•Î•LĞNÔŒ WEST</td>\n",
       "      <td>695000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19909 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year              suburb  avg_property_price\n",
       "0      2006.0              ALBION            152500.0\n",
       "1      2006.0      ALTONA MEADOWS            290000.0\n",
       "2      2006.0   ASPENDALE GARDENS            388600.0\n",
       "3      2006.0         BADDAGINNIE            185000.0\n",
       "4      2006.0              BALWYN            900000.0\n",
       "...       ...                 ...                 ...\n",
       "19904  2024.0            Ğ¡ĞĞ¡KÎ‘TĞĞ            755000.0\n",
       "19905  2024.0           ÔŒLÎ•N IRIS            325000.0\n",
       "19906  2024.0           ÔŒRÎ•Î•NVÎ‘LÎ•            929000.0\n",
       "19907  2024.0           ÔŒRĞVÎ•DÎ‘LÎ•            612250.0\n",
       "19908  2024.0        ÔŒÎ•Î•LĞNÔŒ WEST            695000.0\n",
       "\n",
       "[19909 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average property price by year, suburb\n",
    "final_expanded_df_avg = final_expanded_df.groupby(['year', 'suburb']).agg(\n",
    "    avg_property_price=('property_price_cleaned', 'mean'),\n",
    ").reset_index()\n",
    "final_expanded_df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the leading and trailing whitespaces from the suburb column\n",
    "final_expanded_df_avg['suburb'] = final_expanded_df_avg['suburb'].str.strip()\n",
    "\n",
    "# convert 'year' to int\n",
    "final_expanded_df_avg['year'] = final_expanded_df_avg['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df_avg.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_4_avg.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
