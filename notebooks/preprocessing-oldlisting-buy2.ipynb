{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing oldlisting_buy_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from scripts.utils import create_dir, get_runtime\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (replace with the correct path to your CSV file)\n",
    "file_path = \"../data/landing/oldlistings_buy/oldlistings_buy_2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Helper functions to extract and process data\n",
    "def expand_rented_prices(row):\n",
    "    try:\n",
    "        rent_list = ast.literal_eval(row['rented_prices'])\n",
    "        rows = []\n",
    "        for rent in rent_list:\n",
    "            new_row = row.copy()\n",
    "            new_row['rented_price'] = rent.get('price', None)\n",
    "            new_row['date'] = rent.get('date', None)\n",
    "            rows.append(new_row)\n",
    "        return pd.DataFrame(rows)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return pd.DataFrame([row])\n",
    "\n",
    "def extract_from_meta_data(meta_data_str, label):\n",
    "    try:\n",
    "        meta_list = ast.literal_eval(meta_data_str)\n",
    "        for item in meta_list:\n",
    "            if item.get('label') == label:\n",
    "                return item.get('quantity', None)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Apply the process to expand the first 100 rows (or all rows if needed)\n",
    "expanded_rows = pd.concat([expand_rented_prices(row) for _, row in df.iterrows()], ignore_index=True)\n",
    "\n",
    "# Extract meta_data columns for bed, bath, car, land, type\n",
    "expanded_rows['bed'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bed'))\n",
    "expanded_rows['bath'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bath'))\n",
    "expanded_rows['car'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'car'))\n",
    "expanded_rows['land'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'land'))\n",
    "expanded_rows['type'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'type'))\n",
    "\n",
    "# Keep only relevant columns\n",
    "final_expanded_df = expanded_rows[['lat', 'lng', 'address', 'bed', 'bath', 'car', 'land', 'type', 'rented_price', 'date']]\n",
    "\n",
    "# Optionally, print or view the dataframe\n",
    "# print(final_expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_709/2278130057.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean rented_prices\n",
    "final_expanded_df['property_price_cleaned'] = (\n",
    "    final_expanded_df['rented_price']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_709/2979407506.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')\n"
     ]
    }
   ],
   "source": [
    "# Replace \"O\" with \"0\" in rented_price_cleaned\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_709/2754561085.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace all non-numeric characters with NaN from rented_price_cleaned except for commas and \"$\" signs and \"-\" signs\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and handle range prices by calculating the average\n",
    "def clean_price(price):\n",
    "    if pd.isna(price):\n",
    "        return price  # Return NaN as is\n",
    "    # Handle price ranges like \"$425,000-$455,000\"\n",
    "    range_match = re.match(r\"\\$(\\d+,\\d+)-\\$(\\d+,\\d+)\", price)\n",
    "    if range_match:\n",
    "        low_price = int(range_match.group(1).replace(',', ''))\n",
    "        high_price = int(range_match.group(2).replace(',', ''))\n",
    "        return (low_price + high_price) / 2  # Return the average of the range\n",
    "    # Handle normal prices\n",
    "    price_cleaned = re.sub(r'[^\\d]', '', price)\n",
    "    return int(price_cleaned) if price_cleaned.isdigit() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_709/4207001755.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_709/483767387.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n",
      "/tmp/ipykernel_709/483767387.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_709/2184586359.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['bed_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean \"bed\"\n",
    "final_expanded_df['bed_cleaned'] = (\n",
    "    final_expanded_df['bed']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"bath\"\n",
    "final_expanded_df['bath_cleaned'] = (\n",
    "    final_expanded_df['bath']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"car\"\n",
    "final_expanded_df['car_cleaned'] = (\n",
    "    final_expanded_df['car']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace('𝙻', 'L')\n",
    "    .str.replace('𝙺', 'K')\n",
    "    .str.replace('𝙹', 'J')\n",
    "    .str.replace('𝙸', 'I')\n",
    "    .str.replace('𝙷', 'H')\n",
    "    .str.replace('𝙶', 'G')\n",
    "    .str.replace('𝙵', 'F')\n",
    "    .str.replace('𝙴', 'E')\n",
    "    .str.replace('𝙳', 'D')\n",
    "    .str.replace('𝙲', 'C')\n",
    "    .str.replace('𝙱', 'B')\n",
    "    .str.replace('𝙰', 'A')\n",
    "    .str.replace('𝘾', 'C')\n",
    "    .str.replace('𝘽', 'B')\n",
    "    .str.replace('𝘼', 'A')\n",
    "    .str.replace('𝘿', 'D')\n",
    "    .str.replace('𝘾', 'C')\n",
    "    .str.replace('𝘽', 'B')\n",
    "    .str.replace('𝘼', 'A')\n",
    "    .str.replace('𝘻', 'z')\n",
    "    .str.replace('𝘺', 'y')\n",
    "    .str.replace('𝘹', 'x')\n",
    "    .str.replace('𝘸', 'w')\n",
    "    .str.replace('𝘷', 'v')\n",
    "    .str.replace('𝘶', 'u')\n",
    "    .str.replace('𝘵', 't')\n",
    "    .str.replace('𝘴', 's')\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address_cleaned']\n",
    "    .str.replace('𝘳', 'r')\n",
    "    .str.replace('𝘲', 'q')\n",
    "    .str.replace('𝘱', 'p')\n",
    "    .str.replace('𝘰', 'o')\n",
    "    .str.replace('𝘯', 'n')\n",
    "    .str.replace('𝘭', 'l')\n",
    "    .str.replace('𝘬', 'k')\n",
    "    .str.replace('𝘫', 'j')\n",
    "    .str.replace('𝘪', 'i')\n",
    "    .str.replace('𝘩', 'h')\n",
    "    .str.replace('𝘨', 'g')\n",
    "    .str.replace('𝘧', 'f')\n",
    "    .str.replace('𝘦', 'e')\n",
    "    .str.replace('𝘥', 'd')\n",
    "    .str.replace('𝘣', 'b')\n",
    "    .str.replace('𝘢', 'a')\n",
    "    .str.replace('𝘡', 'Z')\n",
    "    .str.replace('𝘠', 'Y')\n",
    "    .str.replace('𝘟', 'X')\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "final_expanded_df = final_expanded_df.drop(columns=['rented_price', 'bed', 'bath', 'car', 'land', 'address'])\n",
    " \n",
    "# Extract year from date\n",
    "final_expanded_df['year'] = final_expanded_df['date'].dt.year\n",
    "\n",
    "# Extract suburb from address_cleaned, which is all text after the last comma\n",
    "final_expanded_df['suburb'] = final_expanded_df['address_cleaned'].str.rsplit(',').str[-1]\n",
    "\n",
    "# Remove all type that are not 'House' or 'Unit/ampt'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['type'].isin(['House', 'Unit/apmt'])]\n",
    "\n",
    "# Remove all rows with NaN in 'property_price_cleaned'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_expanded_df['bed_cleaned'] = pd.to_numeric(final_expanded_df['bed_cleaned'], errors='coerce')\n",
    "final_expanded_df['bath_cleaned'] = pd.to_numeric(final_expanded_df['bath_cleaned'], errors='coerce')\n",
    "final_expanded_df['car_cleaned'] = pd.to_numeric(final_expanded_df['car_cleaned'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>property_price_cleaned</th>\n",
       "      <th>bed_cleaned</th>\n",
       "      <th>bath_cleaned</th>\n",
       "      <th>car_cleaned</th>\n",
       "      <th>address_cleaned</th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21 CAMBRIDGE ROAD, MОՍNT MART​HA</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>MОՍNT MART​HA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2012-09-01</td>\n",
       "      <td>950000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11 BIRDROCK AVENUE, MOUNT MARTHA</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>MOUNT MARTHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31 HARRAP ROAD, MOUNT MARTHA</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>MOUNT MARTHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2011-08-01</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31 HARRAP ROAD, MOUNT MARTHA</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>MOUNT MARTHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31 HARRAP ROAD, MOUNT MARTHA</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>MOUNT MARTHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518614</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>560000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6 AQUILLA COURT, CHELSE​A HΕIԌHTS</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>CHELSE​A HΕIԌHTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518616</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>490000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2​24 WΕLLS RОΑD , СHΕLSΕΑ HEIGH​TS</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>СHΕLSΕΑ HEIGH​TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518619</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14 CLAROOD CRESCENT, СHΕLSΕΑ HEIGH​TS</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>СHΕLSΕΑ HEIGH​TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518620</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14 CLA​ROOD CRE​S , CHELSEA HEIGHTS</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>CHELSEA HEIGHTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518621</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>6400000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3 OLIVE CRT, CHELSEA HEIGHTS</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>CHELSEA HEIGHTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195935 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat  lng   type       date  property_price_cleaned  bed_cleaned  \\\n",
       "0       NaN  NaN  House 2012-12-01                600000.0          NaN   \n",
       "1       NaN  NaN  House 2012-09-01                950000.0          4.0   \n",
       "2       NaN  NaN  House 2012-10-01                520000.0          NaN   \n",
       "3       NaN  NaN  House 2011-08-01                500000.0          NaN   \n",
       "4       NaN  NaN  House 2011-09-01                500000.0          NaN   \n",
       "...     ...  ...    ...        ...                     ...          ...   \n",
       "518614  NaN  NaN  House 2011-02-01                560000.0          4.0   \n",
       "518616  NaN  NaN  House 2016-08-01                490000.0          3.0   \n",
       "518619  NaN  NaN  House 2016-08-01                     0.0          4.0   \n",
       "518620  NaN  NaN  House 2016-08-01                     0.0          4.0   \n",
       "518621  NaN  NaN  House 2016-08-01               6400000.0          NaN   \n",
       "\n",
       "        bath_cleaned  car_cleaned                         address_cleaned  \\\n",
       "0                2.0          2.0        21 CAMBRIDGE ROAD, MОՍNT MART​HA   \n",
       "1                3.0          2.0        11 BIRDROCK AVENUE, MOUNT MARTHA   \n",
       "2                2.0          2.0            31 HARRAP ROAD, MOUNT MARTHA   \n",
       "3                2.0          2.0            31 HARRAP ROAD, MOUNT MARTHA   \n",
       "4                2.0          2.0            31 HARRAP ROAD, MOUNT MARTHA   \n",
       "...              ...          ...                                     ...   \n",
       "518614           2.0          1.0       6 AQUILLA COURT, CHELSE​A HΕIԌHTS   \n",
       "518616           1.0          NaN     2​24 WΕLLS RОΑD , СHΕLSΕΑ HEIGH​TS    \n",
       "518619           1.0          2.0  14 CLAROOD CRESCENT, СHΕLSΕΑ HEIGH​TS    \n",
       "518620           1.0          2.0     14 CLA​ROOD CRE​S , CHELSEA HEIGHTS   \n",
       "518621           1.0          3.0            3 OLIVE CRT, CHELSEA HEIGHTS   \n",
       "\n",
       "          year              suburb  \n",
       "0       2012.0       MОՍNT MART​HA  \n",
       "1       2012.0        MOUNT MARTHA  \n",
       "2       2012.0        MOUNT MARTHA  \n",
       "3       2011.0        MOUNT MARTHA  \n",
       "4       2011.0        MOUNT MARTHA  \n",
       "...        ...                 ...  \n",
       "518614  2011.0    CHELSE​A HΕIԌHTS  \n",
       "518616  2016.0   СHΕLSΕΑ HEIGH​TS   \n",
       "518619  2016.0   СHΕLSΕΑ HEIGH​TS   \n",
       "518620  2016.0     CHELSEA HEIGHTS  \n",
       "518621  2016.0     CHELSEA HEIGHTS  \n",
       "\n",
       "[195935 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the column 'property_price_cleaned', remove the rows that digits are more than 10\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].astype(str).str.len() <= 10]\n",
    "final_expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "      <th>avg_property_price</th>\n",
       "      <th>avg_bed</th>\n",
       "      <th>avg_bath</th>\n",
       "      <th>avg_car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>AIRP​ORT WΕST</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALT​ONA MEADOWS​</td>\n",
       "      <td>379000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ARDEER</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ASCOT VALE</td>\n",
       "      <td>364500.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>BAIRNSDALE</td>\n",
       "      <td>484875.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42464</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​TRARALGON</td>\n",
       "      <td>399000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42465</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​TULLAMARINE</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42466</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WANGARATTA</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42467</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WARRACKNABEAL</td>\n",
       "      <td>199000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42468</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WHITTLESEA</td>\n",
       "      <td>505000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42469 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year              suburb  avg_property_price  avg_bed  avg_bath  \\\n",
       "0      2006.0       AIRP​ORT WΕST            590000.0      4.0       3.0   \n",
       "1      2006.0   ALT​ONA MEADOWS​             379000.0      5.0       2.0   \n",
       "2      2006.0              ARDEER            225000.0      3.0       NaN   \n",
       "3      2006.0          ASCOT VALE            364500.0      2.6       1.0   \n",
       "4      2006.0          BAIRNSDALE            484875.0      NaN       NaN   \n",
       "...       ...                 ...                 ...      ...       ...   \n",
       "42464  2024.0          ​TRARALGON            399000.0      2.0       1.0   \n",
       "42465  2024.0        ​TULLAMARINE            720000.0      4.0       2.0   \n",
       "42466  2024.0        ​WANGARATTA             400000.0      2.0       1.0   \n",
       "42467  2024.0      ​WARRACKNABEAL            199000.0      3.0       1.0   \n",
       "42468  2024.0         ​WHITTLESEA            505000.0      3.0       1.0   \n",
       "\n",
       "       avg_car  \n",
       "0          2.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          1.0  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "42464      1.0  \n",
       "42465      6.0  \n",
       "42466      2.0  \n",
       "42467      3.0  \n",
       "42468      NaN  \n",
       "\n",
       "[42469 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average property price, average bed amount, average bath amount, average car amount by year, suburb\n",
    "final_expanded_df_avg = final_expanded_df.groupby(['year', 'suburb']).agg(\n",
    "    avg_property_price=('property_price_cleaned', 'mean'),\n",
    "    avg_bed=('bed_cleaned', 'mean'),\n",
    "    avg_bath=('bath_cleaned', 'mean'),\n",
    "    avg_car=('car_cleaned', 'mean')\n",
    ").reset_index()\n",
    "final_expanded_df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df_avg.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_2_avg.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
