{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing oldlisting_buy_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from scripts.utils import create_dir, get_runtime\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (replace with the correct path to your CSV file)\n",
    "file_path = \"../data/landing/oldlistings_buy/oldlistings_buy_6.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Helper functions to extract and process data\n",
    "def expand_rented_prices(row):\n",
    "    try:\n",
    "        rent_list = ast.literal_eval(row['rented_prices'])\n",
    "        rows = []\n",
    "        for rent in rent_list:\n",
    "            new_row = row.copy()\n",
    "            new_row['rented_price'] = rent.get('price', None)\n",
    "            new_row['date'] = rent.get('date', None)\n",
    "            rows.append(new_row)\n",
    "        return pd.DataFrame(rows)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return pd.DataFrame([row])\n",
    "\n",
    "def extract_from_meta_data(meta_data_str, label):\n",
    "    try:\n",
    "        meta_list = ast.literal_eval(meta_data_str)\n",
    "        for item in meta_list:\n",
    "            if item.get('label') == label:\n",
    "                return item.get('quantity', None)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Apply the process to expand the first 100 rows (or all rows if needed)\n",
    "expanded_rows = pd.concat([expand_rented_prices(row) for _, row in df.iterrows()], ignore_index=True)\n",
    "\n",
    "# Extract meta_data columns for bed, bath, car, land, type\n",
    "expanded_rows['bed'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bed'))\n",
    "expanded_rows['bath'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'bath'))\n",
    "expanded_rows['car'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'car'))\n",
    "expanded_rows['land'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'land'))\n",
    "expanded_rows['type'] = expanded_rows['meta_data'].apply(lambda x: extract_from_meta_data(x, 'type'))\n",
    "\n",
    "# Keep only relevant columns\n",
    "final_expanded_df = expanded_rows[['lat', 'lng', 'address', 'bed', 'bath', 'car', 'land', 'type', 'rented_price', 'date']]\n",
    "\n",
    "# Optionally, print or view the dataframe\n",
    "# print(final_expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4225/2278130057.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean rented_prices\n",
    "final_expanded_df['property_price_cleaned'] = (\n",
    "    final_expanded_df['rented_price']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4225/2979407506.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')\n"
     ]
    }
   ],
   "source": [
    "# Replace \"O\" with \"0\" in rented_price_cleaned\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace('O', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4225/2754561085.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace all non-numeric characters with NaN from rented_price_cleaned except for commas and \"$\" signs and \"-\" signs\n",
    "final_expanded_df['property_price_cleaned'] = final_expanded_df['property_price_cleaned'].str.replace(r'[^0-9,$-]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and handle range prices by calculating the average\n",
    "def clean_price(price):\n",
    "    if pd.isna(price):\n",
    "        return price  # Return NaN as is\n",
    "    # Handle price ranges like \"$425,000-$455,000\"\n",
    "    range_match = re.match(r\"\\$(\\d+,\\d+)-\\$(\\d+,\\d+)\", price)\n",
    "    if range_match:\n",
    "        low_price = int(range_match.group(1).replace(',', ''))\n",
    "        high_price = int(range_match.group(2).replace(',', ''))\n",
    "        return (low_price + high_price) / 2  # Return the average of the range\n",
    "    # Handle normal prices\n",
    "    price_cleaned = re.sub(r'[^\\d]', '', price)\n",
    "    return int(price_cleaned) if price_cleaned.isdigit() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4225/4207001755.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['property_price_cleaned'] = [clean_price(price) for price in final_expanded_df['property_price_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4225/483767387.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n",
      "/tmp/ipykernel_4225/483767387.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "final_expanded_df['date'] = pd.to_datetime(final_expanded_df['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4225/2184586359.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_expanded_df['bed_cleaned'] = (\n"
     ]
    }
   ],
   "source": [
    "# Function to clean \"bed\"\n",
    "final_expanded_df['bed_cleaned'] = (\n",
    "    final_expanded_df['bed']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"bath\"\n",
    "final_expanded_df['bath_cleaned'] = (\n",
    "    final_expanded_df['bath']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"car\"\n",
    "final_expanded_df['car_cleaned'] = (\n",
    "    final_expanded_df['car']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    #.str.translate(translation_table)                 # Convert full-width digits to ASCII digits\n",
    "    # Convert full-width digits to ASCII digits\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    .str.replace('𝟌', '4')\n",
    "    .str.replace('𝟋', '3')\n",
    "    .str.replace('𝟊', '2')\n",
    "    .str.replace('𝟉', '1')\n",
    "    .str.replace('𝟈', '0')\n",
    "    .str.replace('𝟇', '9')\n",
    "    .str.replace('𝟆', '8')\n",
    "    .str.replace('𝟅', '7')\n",
    "    .str.replace('𝟄', '6')\n",
    "    .str.replace('𝟃', '5')\n",
    "    .str.replace('𝟂', '4')\n",
    "    .str.replace('𝟁', '3')\n",
    "    .str.replace('𝟀', '2')\n",
    "    .str.replace('𝞿', '1')\n",
    "    .str.replace('𝞾', '0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address']\n",
    "    .str.replace(r'\\u200b', '', regex=False)           # Remove zero-width space\n",
    "    .str.replace(r'\\xa0', '', regex=False)             # Remove non-breaking space\n",
    "    .str.replace(r'<span>', '', regex=False)           # Remove <span> tag\n",
    "    .str.replace(r'</span>', '', regex=False)          # Remove </span> tag\n",
    "    .str.replace('𝙻', 'L')\n",
    "    .str.replace('𝙺', 'K')\n",
    "    .str.replace('𝙹', 'J')\n",
    "    .str.replace('𝙸', 'I')\n",
    "    .str.replace('𝙷', 'H')\n",
    "    .str.replace('𝙶', 'G')\n",
    "    .str.replace('𝙵', 'F')\n",
    "    .str.replace('𝙴', 'E')\n",
    "    .str.replace('𝙳', 'D')\n",
    "    .str.replace('𝙲', 'C')\n",
    "    .str.replace('𝙱', 'B')\n",
    "    .str.replace('𝙰', 'A')\n",
    "    .str.replace('𝘾', 'C')\n",
    "    .str.replace('𝘽', 'B')\n",
    "    .str.replace('𝘼', 'A')\n",
    "    .str.replace('𝘿', 'D')\n",
    "    .str.replace('𝘾', 'C')\n",
    "    .str.replace('𝘽', 'B')\n",
    "    .str.replace('𝘼', 'A')\n",
    "    .str.replace('𝘻', 'z')\n",
    "    .str.replace('𝘺', 'y')\n",
    "    .str.replace('𝘹', 'x')\n",
    "    .str.replace('𝘸', 'w')\n",
    "    .str.replace('𝘷', 'v')\n",
    "    .str.replace('𝘶', 'u')\n",
    "    .str.replace('𝘵', 't')\n",
    "    .str.replace('𝘴', 's')\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean \"address\"\n",
    "final_expanded_df['address_cleaned'] = (\n",
    "    final_expanded_df['address_cleaned']\n",
    "    .str.replace('𝘳', 'r')\n",
    "    .str.replace('𝘲', 'q')\n",
    "    .str.replace('𝘱', 'p')\n",
    "    .str.replace('𝘰', 'o')\n",
    "    .str.replace('𝘯', 'n')\n",
    "    .str.replace('𝘭', 'l')\n",
    "    .str.replace('𝘬', 'k')\n",
    "    .str.replace('𝘫', 'j')\n",
    "    .str.replace('𝘪', 'i')\n",
    "    .str.replace('𝘩', 'h')\n",
    "    .str.replace('𝘨', 'g')\n",
    "    .str.replace('𝘧', 'f')\n",
    "    .str.replace('𝘦', 'e')\n",
    "    .str.replace('𝘥', 'd')\n",
    "    .str.replace('𝘣', 'b')\n",
    "    .str.replace('𝘢', 'a')\n",
    "    .str.replace('𝘡', 'Z')\n",
    "    .str.replace('𝘠', 'Y')\n",
    "    .str.replace('𝘟', 'X')\n",
    "    .str.replace('０', '0')\n",
    "    .str.replace('１', '1')\n",
    "    .str.replace('２', '2')\n",
    "    .str.replace('３', '3')\n",
    "    .str.replace('４', '4')\n",
    "    .str.replace('５', '5')\n",
    "    .str.replace('６', '6')\n",
    "    .str.replace('７', '7')\n",
    "    .str.replace('８', '8')\n",
    "    .str.replace('９', '9')\n",
    "    .str.replace('4', '4')\n",
    "    .str.replace('𝟻', '5')\n",
    "    .str.replace('𝟼', '6')\n",
    "    .str.replace('𝟽', '7')\n",
    "    .str.replace('𝟾', '8')\n",
    "    .str.replace('𝟿', '9')\n",
    "    .str.replace('𝟶', '0')\n",
    "    .str.replace('𝟹', '3')\n",
    "    .str.replace('𝟺', '4')\n",
    "    .str.replace('𝟸', '2')\n",
    "    .str.replace('𝟷', '1')\n",
    "    .str.replace('𝟫', '9')\n",
    "    .str.replace('𝟪', '8')\n",
    "    .str.replace('𝟩', '7')\n",
    "    .str.replace('𝟨', '6')\n",
    "    .str.replace('𝟧', '5')\n",
    "    .str.replace('𝟦', '4')\n",
    "    .str.replace('𝟥', '3')\n",
    "    .str.replace('𝟤', '2')\n",
    "    .str.replace('𝟣', '1')\n",
    "    .str.replace('𝟢', '0')\n",
    "    .str.replace('𝟡', '9')\n",
    "    .str.replace('𝟠', '8')\n",
    "    .str.replace('𝟟', '7')\n",
    "    .str.replace('𝟞', '6')\n",
    "    .str.replace('𝟝', '5')\n",
    "    .str.replace('𝟜', '4')\n",
    "    .str.replace('𝟛', '3')\n",
    "    .str.replace('𝟚', '2')\n",
    "    .str.replace('𝟙', '1')\n",
    "    .str.replace('𝟘', '0')\n",
    "    .str.replace('𝟗', '9')\n",
    "    .str.replace('𝟖', '8')\n",
    "    .str.replace('𝟕', '7')\n",
    "    .str.replace('𝟔', '6')\n",
    "    .str.replace('𝟓', '5')\n",
    "    .str.replace('𝟒', '4')\n",
    "    .str.replace('𝟑', '3')\n",
    "    .str.replace('𝟐', '2')\n",
    "    .str.replace('𝟏', '1')\n",
    "    .str.replace('𝟎', '0')\n",
    "    \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns\n",
    "final_expanded_df = final_expanded_df.drop(columns=['rented_price', 'bed', 'bath', 'car', 'land', 'address'])\n",
    " \n",
    "# Extract year from date\n",
    "final_expanded_df['year'] = final_expanded_df['date'].dt.year\n",
    "\n",
    "# Extract suburb from address_cleaned, which is all text after the last comma\n",
    "final_expanded_df['suburb'] = final_expanded_df['address_cleaned'].str.rsplit(',').str[-1]\n",
    "\n",
    "# Remove all type that are not 'House' or 'Unit/ampt'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['type'].isin(['House', 'Unit/apmt'])]\n",
    "\n",
    "# Remove all rows with NaN in 'property_price_cleaned'\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_expanded_df['bed_cleaned'] = pd.to_numeric(final_expanded_df['bed_cleaned'], errors='coerce')\n",
    "final_expanded_df['bath_cleaned'] = pd.to_numeric(final_expanded_df['bath_cleaned'], errors='coerce')\n",
    "final_expanded_df['car_cleaned'] = pd.to_numeric(final_expanded_df['car_cleaned'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>property_price_cleaned</th>\n",
       "      <th>bed_cleaned</th>\n",
       "      <th>bath_cleaned</th>\n",
       "      <th>car_cleaned</th>\n",
       "      <th>address_cleaned</th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>1525000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211 BARKLY STREET, BRUNSWIC​K</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>BRUNSWIC​K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2011-04-01</td>\n",
       "      <td>989000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211 BARKLY STREET, BRUNSWIC​K</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>BRUNSWIC​K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2011-04-01</td>\n",
       "      <td>999000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211 BARKLY STREET, BRUNSWIC​K</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>BRUNSWIC​K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>525000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>616/601 SYDNEY ROAD, BRUNSWICK</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>BRUNSWICK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unit/apmt</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>610000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>616/601 SYDNEY ROAD, BRUNSWICK</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>BRUNSWICK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325408</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58 SPΕСTΑСLΕ СRΕSСΕNT, PОINT СООK</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>PОINT СООK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325409</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>​12 YOSEMI​TE STRΕΕT , PОINT СООK</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>PОINT СООK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325411</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>​12 YOSEMI​TE STRΕΕT , PОINT СООK</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>PОINT СООK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325412</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>645000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5/32 SANDLEWOOD LANE, POINT COOK</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>POINT COOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325423</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7 BRIMBLE STREET, PОINT СООK</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>PОINT СООK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122491 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat  lng       type       date  property_price_cleaned  bed_cleaned  \\\n",
       "1       NaN  NaN      House 2022-10-01               1525000.0          4.0   \n",
       "3       NaN  NaN      House 2011-04-01                989000.0          4.0   \n",
       "4       NaN  NaN      House 2011-04-01                999000.0          4.0   \n",
       "5       NaN  NaN  Unit/apmt 2022-07-01                525000.0          2.0   \n",
       "6       NaN  NaN  Unit/apmt 2018-02-01                610000.0          2.0   \n",
       "...     ...  ...        ...        ...                     ...          ...   \n",
       "325408  NaN  NaN      House 2018-01-01                590000.0          4.0   \n",
       "325409  NaN  NaN      House 2018-01-01                550000.0          4.0   \n",
       "325411  NaN  NaN      House 2017-04-01                270000.0          4.0   \n",
       "325412  NaN  NaN      House 2018-01-01                645000.0          4.0   \n",
       "325423  NaN  NaN      House 2015-03-01                450000.0          4.0   \n",
       "\n",
       "        bath_cleaned  car_cleaned                    address_cleaned    year  \\\n",
       "1                1.0          1.0      211 BARKLY STREET, BRUNSWIC​K  2022.0   \n",
       "3                1.0          1.0      211 BARKLY STREET, BRUNSWIC​K  2011.0   \n",
       "4                1.0          1.0      211 BARKLY STREET, BRUNSWIC​K  2011.0   \n",
       "5                2.0          2.0     616/601 SYDNEY ROAD, BRUNSWICK  2022.0   \n",
       "6                2.0          2.0     616/601 SYDNEY ROAD, BRUNSWICK  2018.0   \n",
       "...              ...          ...                                ...     ...   \n",
       "325408           2.0          2.0  58 SPΕСTΑСLΕ СRΕSСΕNT, PОINT СООK  2018.0   \n",
       "325409           2.0          2.0  ​12 YOSEMI​TE STRΕΕT , PОINT СООK  2018.0   \n",
       "325411           2.0          2.0  ​12 YOSEMI​TE STRΕΕT , PОINT СООK  2017.0   \n",
       "325412           2.0          2.0   5/32 SANDLEWOOD LANE, POINT COOK  2018.0   \n",
       "325423           2.0          2.0      7 BRIMBLE STREET, PОINT СООK   2015.0   \n",
       "\n",
       "              suburb  \n",
       "1         BRUNSWIC​K  \n",
       "3         BRUNSWIC​K  \n",
       "4         BRUNSWIC​K  \n",
       "5          BRUNSWICK  \n",
       "6          BRUNSWICK  \n",
       "...              ...  \n",
       "325408    PОINT СООK  \n",
       "325409    PОINT СООK  \n",
       "325411    PОINT СООK  \n",
       "325412    POINT COOK  \n",
       "325423   PОINT СООK   \n",
       "\n",
       "[122491 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the column 'property_price_cleaned', remove the rows that digits are more than 10\n",
    "final_expanded_df = final_expanded_df[final_expanded_df['property_price_cleaned'].astype(str).str.len() <= 10]\n",
    "final_expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>suburb</th>\n",
       "      <th>avg_property_price</th>\n",
       "      <th>avg_bed</th>\n",
       "      <th>avg_bath</th>\n",
       "      <th>avg_car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALPHINGTON</td>\n",
       "      <td>680000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ALTONA MEADOWS</td>\n",
       "      <td>251250.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ARDEER</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ARMADALE</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>ASCOT VALE</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30470</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​SOUTHBANK</td>\n",
       "      <td>383000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30471</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WERRIBEE</td>\n",
       "      <td>432000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30472</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WEST MELBOURNE​</td>\n",
       "      <td>577500.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30473</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WODONGA</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30474</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>​WOLLERT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30475 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year             suburb  avg_property_price  avg_bed  avg_bath  \\\n",
       "0      2006.0         ALPHINGTON            680000.0      3.0       2.0   \n",
       "1      2006.0     ALTONA MEADOWS            251250.0      3.0       1.5   \n",
       "2      2006.0             ARDEER            220000.0      3.0       1.0   \n",
       "3      2006.0           ARMADALE            315000.0      3.0       1.0   \n",
       "4      2006.0         ASCOT VALE            500000.0      NaN       2.0   \n",
       "...       ...                ...                 ...      ...       ...   \n",
       "30470  2024.0        ​SOUTHBANK             383000.0      1.0       1.0   \n",
       "30471  2024.0         ​WERRIBEE             432000.0      4.0       NaN   \n",
       "30472  2024.0   ​WEST MELBOURNE​            577500.0      2.0       1.0   \n",
       "30473  2024.0           ​WODONGA            600000.0      3.0       2.0   \n",
       "30474  2024.0          ​WOLLERT                  0.0      4.0       2.0   \n",
       "\n",
       "       avg_car  \n",
       "0          2.0  \n",
       "1          1.0  \n",
       "2          6.0  \n",
       "3          1.0  \n",
       "4          2.0  \n",
       "...        ...  \n",
       "30470      NaN  \n",
       "30471      2.0  \n",
       "30472      1.0  \n",
       "30473      2.0  \n",
       "30474      2.0  \n",
       "\n",
       "[30475 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average property price, average bed amount, average bath amount, average car amount by year, suburb\n",
    "final_expanded_df_avg = final_expanded_df.groupby(['year', 'suburb']).agg(\n",
    "    avg_property_price=('property_price_cleaned', 'mean'),\n",
    "    avg_bed=('bed_cleaned', 'mean'),\n",
    "    avg_bath=('bath_cleaned', 'mean'),\n",
    "    avg_car=('car_cleaned', 'mean')\n",
    ").reset_index()\n",
    "final_expanded_df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/raw/oldlistings_buy/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"../data/raw/oldlistings_buy/\")\n",
    "final_expanded_df_avg.to_csv(\"../data/raw/oldlistings_buy/oldlistings_buy_6_avg.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
